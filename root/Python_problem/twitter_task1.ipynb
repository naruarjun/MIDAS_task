{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYTHON TASK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 3 cells just set up tweepy and import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import API\n",
    "from tweepy import Cursor\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from collections import Counter\n",
    "import sys\n",
    "import json\n",
    "from textwrap import TextWrapper\n",
    "from tabulate import tabulate\n",
    "tabulate.PRESERVE_WHITESPACE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key=\"\"\n",
    "consumer_secret=\"\"\n",
    "access_token=\"\"\n",
    "access_token_secret=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "auth_api = API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we take the tweets and put them into the JSONlines file. We create a cursor and iterate through it to get each status and store them in output.jsonl.\n",
    "At this point I am extracting 200 tweets.If more are desired then the value of no_tweet can be changes accordingly as long as it is less than 3200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'midasIIITD'\n",
    "no_tweets = 100\n",
    "i=0\n",
    "flag=0\n",
    "with jsonlines.open('output.jsonl', mode='w') as writer:\n",
    "    for status in Cursor(auth_api.user_timeline, id=target,tweet_mode='extended').items():\n",
    "        i=i+1\n",
    "        json_string = json.dumps(status._json)\n",
    "        writer.write(json_string)\n",
    "        if i==no_tweets:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we access the file and extract the needed attributes that is full_text,created_at,favourite_count,retweet_count and the extended_entities is used to check for the photos. Here I display 20 tweets and their statistics. Photo Count is empty in tweets with no photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TextWrapper(width=80)\n",
    "disp = 20\n",
    "i=0\n",
    "with jsonlines.open('output.jsonl') as reader:\n",
    "    for obj in reader:\n",
    "        i=i+1\n",
    "        no_photos = 0\n",
    "        obj = json.loads(obj)\n",
    "        try:\n",
    "            for photo in obj[\"extended_entities\"][\"media\"]:\n",
    "                if(photo[\"type\"]=='photo'):\n",
    "                    no_photos=no_photos+1\n",
    "        except:\n",
    "            no_photos = 0\n",
    "        if(no_photos==0):\n",
    "            no_photos=None\n",
    "        print(tabulate([['Text',t.fill(obj['full_text'])],['Date and time',obj['created_at']],['Favourites',obj['favorite_count']],['Retweets',obj['retweet_count']],['Photo Count',no_photos]],headers=['Category', 'Value'],stralign = \"grid\"))\n",
    "        if(i==disp):\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
