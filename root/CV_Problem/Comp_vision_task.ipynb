{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 3 cells is just getting the data into the  right shape and importing the libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from random_eraser import get_random_eraser\n",
    "import pickle\n",
    "from keras.layers import *\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "with open('./train_image.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f,encoding='utf-8')\n",
    "with open('./train_label.pkl', 'rb') as f:\n",
    "    labels = pickle.load(f,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train_data).reshape(-1,28,28,1)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I create the image data generator. The only augmentation I have used is cutout/random erasing and I have normalized(std=1) the centered(mean=0) the images. These are augmentations that after trial and error worked the best. Cutout greatly improved the accuracy and the normalization and centering greatly increased the speed of training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=True,preprocessing_function=get_random_eraser(v_l=0, v_h=1),featurewise_std_normalization=True)#,vertical_flip=True,width_shift_range=.2,height_shift_range=.2,fill_mode='nearest')\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "# fit parameters from data\n",
    "datagen.fit(train_data)\n",
    "\n",
    "# Configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(train_data, labels, batch_size=9):\n",
    "    # Show 9 images\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(X_batch[i].reshape(img_rows, img_cols),cmap='gray')\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "labels[labels==2]=1\n",
    "labels[labels==3]=2\n",
    "labels[labels==6]=3\n",
    "train_y = np.zeros((labels.shape[0], 4))\n",
    "train_y[np.arange(labels.shape[0]),labels] = 1\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, train_y = shuffle(train_data, train_y, random_state=0)\n",
    "train_data, test_data, train_y, test_y = train_test_split(train_data, train_y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple model to start with, Just a straightforward neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(4, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 100,996\n",
      "Trainable params: 100,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training gives great training accuracy but really bad test accuracy. So let's move onto convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6323 - acc: 0.7501 - val_loss: 4.8744 - val_acc: 0.6800\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5063 - acc: 0.8000 - val_loss: 3.7643 - val_acc: 0.7450\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4659 - acc: 0.8149 - val_loss: 4.1858 - val_acc: 0.7275\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4354 - acc: 0.8261 - val_loss: 5.1050 - val_acc: 0.6663\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4144 - acc: 0.8386 - val_loss: 2.9877 - val_acc: 0.8100\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3997 - acc: 0.8444 - val_loss: 3.4666 - val_acc: 0.7750\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3914 - acc: 0.8438 - val_loss: 4.4283 - val_acc: 0.7125\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3759 - acc: 0.8504 - val_loss: 5.8135 - val_acc: 0.6262\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3555 - acc: 0.8581 - val_loss: 3.3697 - val_acc: 0.7850\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3525 - acc: 0.8599 - val_loss: 3.8450 - val_acc: 0.7512\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3451 - acc: 0.8650 - val_loss: 4.4802 - val_acc: 0.7113\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3330 - acc: 0.8717 - val_loss: 3.5706 - val_acc: 0.7712\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3209 - acc: 0.8729 - val_loss: 4.2554 - val_acc: 0.7312\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3120 - acc: 0.8789 - val_loss: 3.7327 - val_acc: 0.7575\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3088 - acc: 0.8826 - val_loss: 3.6531 - val_acc: 0.7662\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.2937 - acc: 0.8839 - val_loss: 3.9951 - val_acc: 0.7412\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2892 - acc: 0.8896 - val_loss: 3.4999 - val_acc: 0.7762\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.2844 - acc: 0.8894 - val_loss: 4.7466 - val_acc: 0.6950\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.2748 - acc: 0.8962 - val_loss: 4.4280 - val_acc: 0.7137\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.2764 - acc: 0.8929 - val_loss: 5.5574 - val_acc: 0.6438\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.2610 - acc: 0.8992 - val_loss: 4.2364 - val_acc: 0.7325\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.2502 - acc: 0.9042 - val_loss: 5.5663 - val_acc: 0.6475\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.2630 - acc: 0.8962 - val_loss: 4.6873 - val_acc: 0.7025\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.2464 - acc: 0.9053 - val_loss: 5.4708 - val_acc: 0.6525\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.2474 - acc: 0.9061 - val_loss: 6.6606 - val_acc: 0.5750\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.2401 - acc: 0.9075 - val_loss: 4.7871 - val_acc: 0.6937\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.2248 - acc: 0.9142 - val_loss: 5.4449 - val_acc: 0.6538\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.2388 - acc: 0.9056 - val_loss: 5.3652 - val_acc: 0.6562\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.2249 - acc: 0.9146 - val_loss: 5.8839 - val_acc: 0.6300\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.2229 - acc: 0.9169 - val_loss: 5.4285 - val_acc: 0.6525\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.2222 - acc: 0.9176 - val_loss: 7.0426 - val_acc: 0.5575\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2182 - acc: 0.9151 - val_loss: 5.2169 - val_acc: 0.6687\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.2052 - acc: 0.9208 - val_loss: 5.5011 - val_acc: 0.6512\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.2088 - acc: 0.9240 - val_loss: 5.7616 - val_acc: 0.6350\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.2127 - acc: 0.9210 - val_loss: 6.0194 - val_acc: 0.6150\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2000 - acc: 0.9253 - val_loss: 5.7594 - val_acc: 0.6362\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1919 - acc: 0.9292 - val_loss: 5.5628 - val_acc: 0.6438\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.2069 - acc: 0.9211 - val_loss: 5.8952 - val_acc: 0.6288\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1876 - acc: 0.9319 - val_loss: 7.0085 - val_acc: 0.5587\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1857 - acc: 0.9308 - val_loss: 5.1525 - val_acc: 0.6763\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1860 - acc: 0.9322 - val_loss: 5.0986 - val_acc: 0.6775\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1790 - acc: 0.9356 - val_loss: 6.1590 - val_acc: 0.6125\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1800 - acc: 0.9346 - val_loss: 4.4823 - val_acc: 0.7150\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1624 - acc: 0.9397 - val_loss: 7.0836 - val_acc: 0.5537\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1745 - acc: 0.9367 - val_loss: 5.8651 - val_acc: 0.6225\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1677 - acc: 0.9379 - val_loss: 6.8562 - val_acc: 0.5650\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1651 - acc: 0.9357 - val_loss: 5.9995 - val_acc: 0.6238\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1715 - acc: 0.9353 - val_loss: 5.2280 - val_acc: 0.6700\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1608 - acc: 0.9406 - val_loss: 5.9123 - val_acc: 0.6262\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.1699 - acc: 0.9390 - val_loss: 4.6046 - val_acc: 0.7075\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1608 - acc: 0.9462 - val_loss: 5.2925 - val_acc: 0.6675\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1558 - acc: 0.9436 - val_loss: 5.8874 - val_acc: 0.6288\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1629 - acc: 0.9406 - val_loss: 7.0267 - val_acc: 0.5587\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1498 - acc: 0.9486 - val_loss: 6.7284 - val_acc: 0.5713\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.1463 - acc: 0.9479 - val_loss: 6.7470 - val_acc: 0.5763\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1629 - acc: 0.9386 - val_loss: 6.4162 - val_acc: 0.5913\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1506 - acc: 0.9461 - val_loss: 5.9930 - val_acc: 0.6225\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1651 - acc: 0.9401 - val_loss: 5.5588 - val_acc: 0.6462\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1462 - acc: 0.9475 - val_loss: 5.8811 - val_acc: 0.6300\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1565 - acc: 0.9418 - val_loss: 5.6888 - val_acc: 0.6450\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1451 - acc: 0.9492 - val_loss: 6.5405 - val_acc: 0.5913\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1427 - acc: 0.9497 - val_loss: 6.8431 - val_acc: 0.5700\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1358 - acc: 0.9519 - val_loss: 6.9350 - val_acc: 0.5637\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1606 - acc: 0.9418 - val_loss: 5.0241 - val_acc: 0.6863\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1361 - acc: 0.9512 - val_loss: 5.2233 - val_acc: 0.6713\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1399 - acc: 0.9478 - val_loss: 6.5375 - val_acc: 0.5837\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1463 - acc: 0.9457 - val_loss: 4.9131 - val_acc: 0.6887\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1317 - acc: 0.9533 - val_loss: 5.6158 - val_acc: 0.6488\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1321 - acc: 0.9529 - val_loss: 6.8965 - val_acc: 0.5700\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1392 - acc: 0.9531 - val_loss: 6.5482 - val_acc: 0.5837\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.1292 - acc: 0.9550 - val_loss: 6.1285 - val_acc: 0.6150\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1325 - acc: 0.9553 - val_loss: 6.0887 - val_acc: 0.6162\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.1295 - acc: 0.9531 - val_loss: 5.3038 - val_acc: 0.6663\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1347 - acc: 0.9538 - val_loss: 6.9881 - val_acc: 0.5600\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1252 - acc: 0.9557 - val_loss: 5.7510 - val_acc: 0.6412\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1393 - acc: 0.9522 - val_loss: 5.5581 - val_acc: 0.6475\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1270 - acc: 0.9579 - val_loss: 5.9031 - val_acc: 0.6312\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1198 - acc: 0.9596 - val_loss: 5.8288 - val_acc: 0.6350\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1269 - acc: 0.9568 - val_loss: 5.4815 - val_acc: 0.6550\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.1261 - acc: 0.9561 - val_loss: 7.0224 - val_acc: 0.5587\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1144 - acc: 0.9617 - val_loss: 6.5170 - val_acc: 0.5925\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1116 - acc: 0.9603 - val_loss: 6.7820 - val_acc: 0.5725\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1315 - acc: 0.9532 - val_loss: 6.3752 - val_acc: 0.6012\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1225 - acc: 0.9572 - val_loss: 5.7481 - val_acc: 0.6350\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1212 - acc: 0.9601 - val_loss: 5.2252 - val_acc: 0.6725\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1131 - acc: 0.9619 - val_loss: 6.1599 - val_acc: 0.6162\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.1092 - acc: 0.9619 - val_loss: 7.0673 - val_acc: 0.5563\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1289 - acc: 0.9547 - val_loss: 6.4523 - val_acc: 0.5938\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1218 - acc: 0.9574 - val_loss: 8.0377 - val_acc: 0.4975\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1138 - acc: 0.9606 - val_loss: 8.0101 - val_acc: 0.4963\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.1186 - acc: 0.9603 - val_loss: 7.6154 - val_acc: 0.5262\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1133 - acc: 0.9617 - val_loss: 8.4922 - val_acc: 0.4700\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.1123 - acc: 0.9622 - val_loss: 7.4570 - val_acc: 0.5300\n",
      "Epoch 94/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1059 - acc: 0.9636 - val_loss: 8.6345 - val_acc: 0.4587\n",
      "Epoch 95/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1073 - acc: 0.9626 - val_loss: 8.2700 - val_acc: 0.4825\n",
      "Epoch 96/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1174 - acc: 0.9608 - val_loss: 6.9422 - val_acc: 0.5650\n",
      "Epoch 97/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1078 - acc: 0.9640 - val_loss: 6.6402 - val_acc: 0.5850\n",
      "Epoch 98/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1066 - acc: 0.9631 - val_loss: 7.3587 - val_acc: 0.5413\n",
      "Epoch 99/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1122 - acc: 0.9619 - val_loss: 7.4044 - val_acc: 0.5350\n",
      "Epoch 100/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1192 - acc: 0.9625 - val_loss: 6.3137 - val_acc: 0.6025\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(train_data, train_y, batch_size=batch_size),\n",
    "                        steps_per_epoch=train_data.shape[0] // batch_size,\n",
    "                        epochs=100,shuffle = True,validation_data=(test_data, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple convolutional network with some fully connected layers and dropout for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 24, 24, 256)       37120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               9437440   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 9,508,132\n",
      "Trainable params: 9,508,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 11.7572 - acc: 0.2605\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 11.7730 - acc: 0.2642\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 11.5302 - acc: 0.2806\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 11.3392 - acc: 0.2923\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 9.7402 - acc: 0.3855\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 6.7669 - acc: 0.5511\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 3.2035 - acc: 0.6135\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.8840 - acc: 0.6593\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.7510 - acc: 0.7086\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.7014 - acc: 0.7399\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.6617 - acc: 0.7546\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.6146 - acc: 0.7725\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.6022 - acc: 0.7775\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.5823 - acc: 0.7835\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.5693 - acc: 0.7939\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.5559 - acc: 0.7951\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.5429 - acc: 0.7996\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.5323 - acc: 0.8037\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.5176 - acc: 0.8066\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.5208 - acc: 0.8089\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.5165 - acc: 0.8115\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.5007 - acc: 0.8165\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.5074 - acc: 0.8132\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4876 - acc: 0.8216\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4856 - acc: 0.8192\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4805 - acc: 0.8195\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4797 - acc: 0.8236\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4748 - acc: 0.8254\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4688 - acc: 0.8271\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4589 - acc: 0.8314\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4575 - acc: 0.8289\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4613 - acc: 0.8273\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4448 - acc: 0.8353\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4466 - acc: 0.8333\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4405 - acc: 0.8327\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4458 - acc: 0.8376\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4407 - acc: 0.8333\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4407 - acc: 0.8415\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4388 - acc: 0.8397\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4257 - acc: 0.8423\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4320 - acc: 0.8417\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4304 - acc: 0.8413\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4384 - acc: 0.8375\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4221 - acc: 0.8438\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4193 - acc: 0.8434\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4358 - acc: 0.8391\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4176 - acc: 0.8454\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4214 - acc: 0.8478\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4165 - acc: 0.8468\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4145 - acc: 0.8465\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4085 - acc: 0.8452\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4183 - acc: 0.8485\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4082 - acc: 0.8490\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4153 - acc: 0.8490\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4226 - acc: 0.8485\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4012 - acc: 0.8505\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4086 - acc: 0.8431\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4049 - acc: 0.8503\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4080 - acc: 0.8548\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4016 - acc: 0.8531\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3954 - acc: 0.8534\n",
      "Epoch 62/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4080 - acc: 0.8473\n",
      "Epoch 63/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4005 - acc: 0.8544\n",
      "Epoch 64/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3977 - acc: 0.8565\n",
      "Epoch 65/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3858 - acc: 0.8560\n",
      "Epoch 66/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3993 - acc: 0.8479\n",
      "Epoch 67/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4016 - acc: 0.8549\n",
      "Epoch 68/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3837 - acc: 0.8555\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3949 - acc: 0.8558\n",
      "Epoch 70/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3881 - acc: 0.8595\n",
      "Epoch 71/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3919 - acc: 0.8554\n",
      "Epoch 72/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3950 - acc: 0.8538\n",
      "Epoch 73/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3862 - acc: 0.8579\n",
      "Epoch 74/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3927 - acc: 0.8554\n",
      "Epoch 75/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3902 - acc: 0.8566\n",
      "Epoch 76/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3894 - acc: 0.8586\n",
      "Epoch 77/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3898 - acc: 0.8570\n",
      "Epoch 78/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3749 - acc: 0.8602\n",
      "Epoch 79/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3955 - acc: 0.8554\n",
      "Epoch 80/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3821 - acc: 0.8616\n",
      "Epoch 81/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3809 - acc: 0.8616\n",
      "Epoch 82/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3833 - acc: 0.8575\n",
      "Epoch 83/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3863 - acc: 0.8566\n",
      "Epoch 84/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3759 - acc: 0.8584\n",
      "Epoch 85/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3654 - acc: 0.8630\n",
      "Epoch 86/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3838 - acc: 0.8571\n",
      "Epoch 87/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3764 - acc: 0.8576\n",
      "Epoch 88/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3728 - acc: 0.8660\n",
      "Epoch 89/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3711 - acc: 0.8620\n",
      "Epoch 90/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3776 - acc: 0.8595\n",
      "Epoch 91/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3738 - acc: 0.8609\n",
      "Epoch 92/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3731 - acc: 0.8641\n",
      "Epoch 93/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3691 - acc: 0.8629\n",
      "Epoch 94/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3747 - acc: 0.8594\n",
      "Epoch 95/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3850 - acc: 0.8611\n",
      "Epoch 96/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3804 - acc: 0.8625\n",
      "Epoch 97/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3723 - acc: 0.8655\n",
      "Epoch 98/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3691 - acc: 0.8608\n",
      "Epoch 99/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3731 - acc: 0.8655\n",
      "Epoch 100/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3669 - acc: 0.8666\n",
      "Epoch 101/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3563 - acc: 0.8696\n",
      "Epoch 102/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3680 - acc: 0.8634\n",
      "Epoch 103/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3607 - acc: 0.8675\n",
      "Epoch 104/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3559 - acc: 0.8704\n",
      "Epoch 105/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3675 - acc: 0.8656\n",
      "Epoch 106/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3582 - acc: 0.8698\n",
      "Epoch 107/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3594 - acc: 0.8698\n",
      "Epoch 108/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3636 - acc: 0.8625\n",
      "Epoch 109/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3563 - acc: 0.8678\n",
      "Epoch 110/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3534 - acc: 0.8702\n",
      "Epoch 111/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3609 - acc: 0.8701\n",
      "Epoch 112/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3656 - acc: 0.8653\n",
      "Epoch 113/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3638 - acc: 0.8671\n",
      "Epoch 114/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3531 - acc: 0.8688\n",
      "Epoch 115/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3565 - acc: 0.8726\n",
      "Epoch 116/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3631 - acc: 0.8708\n",
      "Epoch 117/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3551 - acc: 0.8691\n",
      "Epoch 118/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3493 - acc: 0.8691\n",
      "Epoch 119/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3615 - acc: 0.8708\n",
      "Epoch 120/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3642 - acc: 0.8666\n",
      "Epoch 121/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3532 - acc: 0.8746\n",
      "Epoch 122/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3563 - acc: 0.8690\n",
      "Epoch 123/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3601 - acc: 0.8736\n",
      "Epoch 124/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3565 - acc: 0.8690\n",
      "Epoch 125/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3580 - acc: 0.8729\n",
      "Epoch 126/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3606 - acc: 0.8731\n",
      "Epoch 127/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3548 - acc: 0.8728\n",
      "Epoch 128/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3486 - acc: 0.8762\n",
      "Epoch 129/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3473 - acc: 0.8730\n",
      "Epoch 130/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3516 - acc: 0.8709\n",
      "Epoch 131/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3501 - acc: 0.8735\n",
      "Epoch 132/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3458 - acc: 0.8705\n",
      "Epoch 133/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3508 - acc: 0.8764\n",
      "Epoch 134/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3391 - acc: 0.8761\n",
      "Epoch 135/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3407 - acc: 0.8746\n",
      "Epoch 136/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3487 - acc: 0.8738\n",
      "Epoch 137/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3496 - acc: 0.8710\n",
      "Epoch 138/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3478 - acc: 0.8743\n",
      "Epoch 139/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3415 - acc: 0.8784\n",
      "Epoch 140/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3395 - acc: 0.8771\n",
      "Epoch 141/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3486 - acc: 0.8743\n",
      "Epoch 142/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3490 - acc: 0.8726\n",
      "Epoch 143/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3317 - acc: 0.8826\n",
      "Epoch 144/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3551 - acc: 0.8711\n",
      "Epoch 145/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3570 - acc: 0.8740\n",
      "Epoch 146/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3374 - acc: 0.8779\n",
      "Epoch 147/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3401 - acc: 0.8759\n",
      "Epoch 148/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3390 - acc: 0.8752\n",
      "Epoch 149/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3417 - acc: 0.8751\n",
      "Epoch 150/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3266 - acc: 0.8808\n",
      "Epoch 151/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3450 - acc: 0.8780\n",
      "Epoch 152/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3430 - acc: 0.8772\n",
      "Epoch 153/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3409 - acc: 0.8771\n",
      "Epoch 154/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3469 - acc: 0.8752\n",
      "Epoch 155/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3375 - acc: 0.8760\n",
      "Epoch 156/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3370 - acc: 0.8801\n",
      "Epoch 157/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3377 - acc: 0.8738\n",
      "Epoch 158/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3376 - acc: 0.8770\n",
      "Epoch 159/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3416 - acc: 0.8754\n",
      "Epoch 160/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3399 - acc: 0.8830\n",
      "Epoch 161/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3393 - acc: 0.8741\n",
      "Epoch 162/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3368 - acc: 0.8772\n",
      "Epoch 163/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3453 - acc: 0.8765\n",
      "Epoch 164/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3416 - acc: 0.8774\n",
      "Epoch 165/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3411 - acc: 0.8799\n",
      "Epoch 166/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3329 - acc: 0.8811\n",
      "Epoch 167/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3346 - acc: 0.8821\n",
      "Epoch 168/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3398 - acc: 0.8756\n",
      "Epoch 169/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3256 - acc: 0.8804\n",
      "Epoch 170/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3291 - acc: 0.8802\n",
      "Epoch 171/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3334 - acc: 0.8831\n",
      "Epoch 172/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3385 - acc: 0.8766\n",
      "Epoch 173/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3405 - acc: 0.8829\n",
      "Epoch 174/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3254 - acc: 0.8810\n",
      "Epoch 175/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3368 - acc: 0.8809\n",
      "Epoch 176/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3369 - acc: 0.8824\n",
      "Epoch 177/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3418 - acc: 0.8776\n",
      "Epoch 178/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3360 - acc: 0.8749\n",
      "Epoch 179/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3223 - acc: 0.8811\n",
      "Epoch 180/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3279 - acc: 0.8814\n",
      "Epoch 181/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3222 - acc: 0.8809\n",
      "Epoch 182/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3300 - acc: 0.8842\n",
      "Epoch 183/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3407 - acc: 0.8755\n",
      "Epoch 184/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3308 - acc: 0.8838\n",
      "Epoch 185/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3305 - acc: 0.8832\n",
      "Epoch 186/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3186 - acc: 0.8875\n",
      "Epoch 187/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3366 - acc: 0.8795\n",
      "Epoch 188/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3260 - acc: 0.8850\n",
      "Epoch 189/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3222 - acc: 0.8814\n",
      "Epoch 190/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3195 - acc: 0.8865\n",
      "Epoch 191/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3292 - acc: 0.8851\n",
      "Epoch 192/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3252 - acc: 0.8814\n",
      "Epoch 193/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3226 - acc: 0.8851\n",
      "Epoch 194/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3205 - acc: 0.8847\n",
      "Epoch 195/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3237 - acc: 0.8808\n",
      "Epoch 196/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3217 - acc: 0.8806\n",
      "Epoch 197/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3288 - acc: 0.8791\n",
      "Epoch 198/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3254 - acc: 0.8821\n",
      "Epoch 199/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3228 - acc: 0.8835\n",
      "Epoch 200/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3232 - acc: 0.8822\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "batch_size = 64\n",
    "num_classes = 7\n",
    "epochs = 10\n",
    "input_shape = (28,28,1)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.85))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.85))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "print(model.summary())\n",
    "datagen.fit(train_data)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "                metrics=['accuracy'])\n",
    "history = model.fit_generator(datagen.flow(train_data, train_y, batch_size=batch_size),\n",
    "                        steps_per_epoch=train_data.shape[0] // batch_size,\n",
    "                        epochs=200,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.2833 - acc: 0.8964\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.2874 - acc: 0.8909\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2831 - acc: 0.8939\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2956 - acc: 0.8948\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2868 - acc: 0.8924\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2809 - acc: 0.8984\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2812 - acc: 0.8989\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2800 - acc: 0.8952\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2827 - acc: 0.8984\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2814 - acc: 0.8967\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2838 - acc: 0.8948\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2889 - acc: 0.8940\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2822 - acc: 0.8984\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2831 - acc: 0.9006\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2773 - acc: 0.9002\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2807 - acc: 0.8975\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2772 - acc: 0.8990\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2801 - acc: 0.8989\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2787 - acc: 0.9010\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2833 - acc: 0.8955\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2833 - acc: 0.8946\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2758 - acc: 0.9006\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2787 - acc: 0.8992\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2792 - acc: 0.9025\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2819 - acc: 0.8986\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2720 - acc: 0.9015\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2825 - acc: 0.8966\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2827 - acc: 0.8964\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2852 - acc: 0.9009\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2707 - acc: 0.9027\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2716 - acc: 0.9014\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2750 - acc: 0.9015\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2750 - acc: 0.9014\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2761 - acc: 0.8985\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2743 - acc: 0.8981\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2859 - acc: 0.8960\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2839 - acc: 0.8960\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2766 - acc: 0.9001\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2714 - acc: 0.8997\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2695 - acc: 0.9022\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2691 - acc: 0.9038\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2776 - acc: 0.9006\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2757 - acc: 0.9002\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2756 - acc: 0.8997\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2772 - acc: 0.9031\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2830 - acc: 0.8996\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2782 - acc: 0.9016\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2775 - acc: 0.8997\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2769 - acc: 0.8978\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2743 - acc: 0.8985\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2789 - acc: 0.8989\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2878 - acc: 0.8945\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2693 - acc: 0.9024\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2818 - acc: 0.8990\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2657 - acc: 0.9038\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2724 - acc: 0.8976\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2613 - acc: 0.9054\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2801 - acc: 0.8979\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2679 - acc: 0.9031\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2762 - acc: 0.9016\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2738 - acc: 0.9029\n",
      "Epoch 62/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2735 - acc: 0.9034\n",
      "Epoch 63/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2779 - acc: 0.8991\n",
      "Epoch 64/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2756 - acc: 0.9009\n",
      "Epoch 65/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2752 - acc: 0.9019\n",
      "Epoch 66/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2723 - acc: 0.9012\n",
      "Epoch 67/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2716 - acc: 0.9006\n",
      "Epoch 68/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2657 - acc: 0.9039\n",
      "Epoch 69/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2727 - acc: 0.9000\n",
      "Epoch 70/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2607 - acc: 0.9052\n",
      "Epoch 71/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2791 - acc: 0.8997\n",
      "Epoch 72/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2760 - acc: 0.8997\n",
      "Epoch 73/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2714 - acc: 0.8997\n",
      "Epoch 74/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2846 - acc: 0.8997\n",
      "Epoch 75/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2780 - acc: 0.8982\n",
      "Epoch 76/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2887 - acc: 0.8971\n",
      "Epoch 77/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2624 - acc: 0.9014\n",
      "Epoch 78/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2770 - acc: 0.8986\n",
      "Epoch 79/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2765 - acc: 0.8971\n",
      "Epoch 80/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2741 - acc: 0.9002\n",
      "Epoch 81/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2666 - acc: 0.9025\n",
      "Epoch 82/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2723 - acc: 0.9021\n",
      "Epoch 83/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2689 - acc: 0.9036\n",
      "Epoch 84/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2727 - acc: 0.9021\n",
      "Epoch 85/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2721 - acc: 0.9021\n",
      "Epoch 86/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2618 - acc: 0.9051\n",
      "Epoch 87/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2678 - acc: 0.8985\n",
      "Epoch 88/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2734 - acc: 0.9000\n",
      "Epoch 89/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2695 - acc: 0.9030\n",
      "Epoch 90/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2668 - acc: 0.9000\n",
      "Epoch 91/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2666 - acc: 0.9056\n",
      "Epoch 92/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2678 - acc: 0.9012\n",
      "Epoch 93/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2717 - acc: 0.9000\n",
      "Epoch 94/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2727 - acc: 0.9035\n",
      "Epoch 95/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2701 - acc: 0.9018\n",
      "Epoch 96/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2722 - acc: 0.8999\n",
      "Epoch 97/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2763 - acc: 0.8978\n",
      "Epoch 98/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2721 - acc: 0.9011\n",
      "Epoch 99/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2635 - acc: 0.9031\n",
      "Epoch 100/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2671 - acc: 0.9032\n",
      "Epoch 101/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2641 - acc: 0.9087\n",
      "Epoch 102/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2637 - acc: 0.9034\n",
      "Epoch 103/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2737 - acc: 0.8986\n",
      "Epoch 104/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2720 - acc: 0.9041\n",
      "Epoch 105/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2699 - acc: 0.9038\n",
      "Epoch 106/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2622 - acc: 0.9025\n",
      "Epoch 107/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2682 - acc: 0.9044\n",
      "Epoch 108/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2660 - acc: 0.9029\n",
      "Epoch 109/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2697 - acc: 0.9002\n",
      "Epoch 110/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2749 - acc: 0.9004\n",
      "Epoch 111/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2744 - acc: 0.9001\n",
      "Epoch 112/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2764 - acc: 0.9029\n",
      "Epoch 113/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2692 - acc: 0.9022\n",
      "Epoch 114/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2640 - acc: 0.9020\n",
      "Epoch 115/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2748 - acc: 0.8992\n",
      "Epoch 116/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2705 - acc: 0.9002\n",
      "Epoch 117/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2711 - acc: 0.9035\n",
      "Epoch 118/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2640 - acc: 0.9042\n",
      "Epoch 119/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2724 - acc: 0.8999\n",
      "Epoch 120/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2785 - acc: 0.9001\n",
      "Epoch 121/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2647 - acc: 0.9038\n",
      "Epoch 122/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2656 - acc: 0.9020\n",
      "Epoch 123/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2749 - acc: 0.8980\n",
      "Epoch 124/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2674 - acc: 0.9022\n",
      "Epoch 125/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2736 - acc: 0.9029\n",
      "Epoch 126/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2710 - acc: 0.9022\n",
      "Epoch 127/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2598 - acc: 0.9060\n",
      "Epoch 128/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2684 - acc: 0.9006\n",
      "Epoch 129/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2743 - acc: 0.9016\n",
      "Epoch 130/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2784 - acc: 0.8996\n",
      "Epoch 131/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2683 - acc: 0.9011\n",
      "Epoch 132/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2817 - acc: 0.9000\n",
      "Epoch 133/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2687 - acc: 0.9039\n",
      "Epoch 134/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2668 - acc: 0.9030\n",
      "Epoch 135/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2761 - acc: 0.8975\n",
      "Epoch 136/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2647 - acc: 0.9026\n",
      "Epoch 137/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2747 - acc: 0.9044\n",
      "Epoch 138/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2705 - acc: 0.8991\n",
      "Epoch 139/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2682 - acc: 0.9038\n",
      "Epoch 140/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2688 - acc: 0.9010\n",
      "Epoch 141/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2617 - acc: 0.9050\n",
      "Epoch 142/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2658 - acc: 0.9022\n",
      "Epoch 143/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2761 - acc: 0.8964\n",
      "Epoch 144/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2658 - acc: 0.9020\n",
      "Epoch 145/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2598 - acc: 0.9049\n",
      "Epoch 146/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2729 - acc: 0.9054\n",
      "Epoch 147/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2757 - acc: 0.8996\n",
      "Epoch 148/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2611 - acc: 0.9057\n",
      "Epoch 149/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2625 - acc: 0.9068\n",
      "Epoch 150/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2707 - acc: 0.8962\n",
      "Epoch 151/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2657 - acc: 0.9050\n",
      "Epoch 152/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2576 - acc: 0.9057\n",
      "Epoch 153/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2633 - acc: 0.9042\n",
      "Epoch 154/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2655 - acc: 0.9032\n",
      "Epoch 155/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2630 - acc: 0.9060\n",
      "Epoch 156/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2709 - acc: 0.8994\n",
      "Epoch 157/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2591 - acc: 0.9046\n",
      "Epoch 158/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2662 - acc: 0.9019\n",
      "Epoch 159/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2658 - acc: 0.9065\n",
      "Epoch 160/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2591 - acc: 0.9054\n",
      "Epoch 161/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2661 - acc: 0.9000\n",
      "Epoch 162/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2703 - acc: 0.9012\n",
      "Epoch 163/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2746 - acc: 0.8989\n",
      "Epoch 164/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2661 - acc: 0.9036\n",
      "Epoch 165/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2781 - acc: 0.9000\n",
      "Epoch 166/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2754 - acc: 0.8976\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2666 - acc: 0.9036\n",
      "Epoch 168/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2758 - acc: 0.9009\n",
      "Epoch 169/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2705 - acc: 0.9044\n",
      "Epoch 170/200\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.2795 - acc: 0.9044\n",
      "Epoch 171/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2588 - acc: 0.9086\n",
      "Epoch 172/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2628 - acc: 0.9035\n",
      "Epoch 173/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2844 - acc: 0.9020\n",
      "Epoch 174/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2803 - acc: 0.9001\n",
      "Epoch 175/200\n",
      "100/125 [=======================>......] - ETA: 0s - loss: 0.2720 - acc: 0.8986"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(lr = 1e-3),\n",
    "                metrics=['accuracy'])\n",
    "history2 = model.fit_generator(datagen.flow(train_data, train_y, batch_size=batch_size),\n",
    "                        steps_per_epoch=train_data.shape[0] // batch_size,\n",
    "                        epochs=200,shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was trained for around 400 epochs. Let's load it and evaluate it. This model was trained on the entire data so the accuracy will be very good. But again it can't be used as we will se later as it doesn't generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# model_json = model.to_json()\n",
    "# with open(\"model_2.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# model.save_weights(\"model_2.h5\")\n",
    "# print(\"Saved model to disk\")\n",
    "json_file = open('model_2.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_2.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 93.88%\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "                metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(test_data, test_y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have started just incrementing one layer at a time and add more regularization via dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 256)       37120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               6553856   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 7,214,628\n",
      "Trainable params: 7,214,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "batch_size = 64\n",
    "num_classes = 7\n",
    "epochs = 10\n",
    "input_shape = (28,28,1)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.85))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.85))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "print(model.summary())\n",
    "datagen.fit(train_data)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "125/125 [==============================] - 4s 31ms/step - loss: 11.8139 - acc: 0.2600\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 11.9170 - acc: 0.2578\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 11.8416 - acc: 0.2625\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 11.7001 - acc: 0.2714\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 11.6148 - acc: 0.2780\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 11.6561 - acc: 0.2755\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 11.5322 - acc: 0.2819\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 11.5625 - acc: 0.2810\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 11.3224 - acc: 0.2965\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 11.2363 - acc: 0.3017\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 10.9338 - acc: 0.3196\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 10.6684 - acc: 0.3355\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 10.4018 - acc: 0.3520\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 10.2778 - acc: 0.3601\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 9.8188 - acc: 0.3867\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 9.7614 - acc: 0.3894\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 9.3492 - acc: 0.4158\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 9.0032 - acc: 0.4381\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 8.7312 - acc: 0.4531\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 8.4559 - acc: 0.4721\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 8.1115 - acc: 0.4904\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 7.2923 - acc: 0.5397\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 6.9889 - acc: 0.5599\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 6.5001 - acc: 0.5913\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 6.4196 - acc: 0.5932\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 6.1580 - acc: 0.6094\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 5.9319 - acc: 0.6186\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 3.0071 - acc: 0.6026\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.8231 - acc: 0.6700\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.7365 - acc: 0.7200\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.6686 - acc: 0.7422\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.6388 - acc: 0.7540\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.6173 - acc: 0.7649\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.6062 - acc: 0.7695\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.5906 - acc: 0.7795\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.5718 - acc: 0.7820\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.5778 - acc: 0.7870\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.5495 - acc: 0.7860\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.5404 - acc: 0.7913\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.5339 - acc: 0.7917\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.5315 - acc: 0.7939\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.5189 - acc: 0.8049\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.5161 - acc: 0.8028\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.5213 - acc: 0.8043\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.5105 - acc: 0.8058\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.5002 - acc: 0.8149\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4907 - acc: 0.8147\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.5054 - acc: 0.8093\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4773 - acc: 0.8170\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4679 - acc: 0.8225\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4731 - acc: 0.8225\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4690 - acc: 0.8234\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4605 - acc: 0.8230\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4627 - acc: 0.8216\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4549 - acc: 0.8300\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4603 - acc: 0.8273\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4483 - acc: 0.8329\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4458 - acc: 0.8323\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4419 - acc: 0.8353\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4448 - acc: 0.8345\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4373 - acc: 0.8363\n",
      "Epoch 62/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4338 - acc: 0.8339\n",
      "Epoch 63/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4304 - acc: 0.8326\n",
      "Epoch 64/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4359 - acc: 0.8349\n",
      "Epoch 65/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4228 - acc: 0.8417\n",
      "Epoch 66/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4222 - acc: 0.8400\n",
      "Epoch 67/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4204 - acc: 0.8466\n",
      "Epoch 68/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4134 - acc: 0.8454\n",
      "Epoch 69/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4161 - acc: 0.8427\n",
      "Epoch 70/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4113 - acc: 0.8449\n",
      "Epoch 71/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4123 - acc: 0.8481\n",
      "Epoch 72/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3993 - acc: 0.8490\n",
      "Epoch 73/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.4018 - acc: 0.8460\n",
      "Epoch 74/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4004 - acc: 0.8524\n",
      "Epoch 75/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3975 - acc: 0.8528\n",
      "Epoch 76/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3913 - acc: 0.8524\n",
      "Epoch 77/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3797 - acc: 0.8584\n",
      "Epoch 78/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4062 - acc: 0.8518\n",
      "Epoch 79/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3867 - acc: 0.8511\n",
      "Epoch 80/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3927 - acc: 0.8539\n",
      "Epoch 81/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3860 - acc: 0.8600\n",
      "Epoch 82/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3847 - acc: 0.8589\n",
      "Epoch 83/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3858 - acc: 0.8499\n",
      "Epoch 84/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3915 - acc: 0.8518\n",
      "Epoch 85/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3745 - acc: 0.8649\n",
      "Epoch 86/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3682 - acc: 0.8609\n",
      "Epoch 87/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3874 - acc: 0.8568\n",
      "Epoch 88/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3585 - acc: 0.8662\n",
      "Epoch 89/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3738 - acc: 0.8638\n",
      "Epoch 90/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3764 - acc: 0.8615\n",
      "Epoch 91/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3769 - acc: 0.8606\n",
      "Epoch 92/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3776 - acc: 0.8639\n",
      "Epoch 93/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3799 - acc: 0.8611\n",
      "Epoch 94/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3658 - acc: 0.8705\n",
      "Epoch 95/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3650 - acc: 0.8648\n",
      "Epoch 96/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3558 - acc: 0.8672\n",
      "Epoch 97/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3647 - acc: 0.8646\n",
      "Epoch 98/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3657 - acc: 0.8664\n",
      "Epoch 99/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3644 - acc: 0.8661\n",
      "Epoch 100/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3605 - acc: 0.8639\n",
      "Epoch 101/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3593 - acc: 0.8709\n",
      "Epoch 102/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3521 - acc: 0.8732\n",
      "Epoch 103/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3450 - acc: 0.8739\n",
      "Epoch 104/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3496 - acc: 0.8695\n",
      "Epoch 105/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3484 - acc: 0.8721\n",
      "Epoch 106/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3517 - acc: 0.8725\n",
      "Epoch 107/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3432 - acc: 0.8731\n",
      "Epoch 108/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3573 - acc: 0.8714\n",
      "Epoch 109/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3464 - acc: 0.8738\n",
      "Epoch 110/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3477 - acc: 0.8774\n",
      "Epoch 111/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3441 - acc: 0.8751\n",
      "Epoch 112/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3362 - acc: 0.8781\n",
      "Epoch 113/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3462 - acc: 0.8730\n",
      "Epoch 114/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3316 - acc: 0.8839\n",
      "Epoch 115/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3158 - acc: 0.8802\n",
      "Epoch 116/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3292 - acc: 0.8822\n",
      "Epoch 117/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3403 - acc: 0.8771\n",
      "Epoch 118/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3426 - acc: 0.8778\n",
      "Epoch 119/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3253 - acc: 0.8790\n",
      "Epoch 120/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3258 - acc: 0.8869\n",
      "Epoch 121/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3207 - acc: 0.8820\n",
      "Epoch 122/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3268 - acc: 0.8816\n",
      "Epoch 123/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3244 - acc: 0.8838\n",
      "Epoch 124/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3171 - acc: 0.8841\n",
      "Epoch 125/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3088 - acc: 0.8912\n",
      "Epoch 126/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3094 - acc: 0.8877\n",
      "Epoch 127/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3232 - acc: 0.8844\n",
      "Epoch 128/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3165 - acc: 0.8875\n",
      "Epoch 129/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3175 - acc: 0.8862\n",
      "Epoch 130/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3131 - acc: 0.8876\n",
      "Epoch 131/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3227 - acc: 0.8835\n",
      "Epoch 132/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3170 - acc: 0.8872\n",
      "Epoch 133/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3051 - acc: 0.8882\n",
      "Epoch 134/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3185 - acc: 0.8839\n",
      "Epoch 135/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3198 - acc: 0.8880\n",
      "Epoch 136/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3007 - acc: 0.8949\n",
      "Epoch 137/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3150 - acc: 0.8891\n",
      "Epoch 138/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3117 - acc: 0.8879\n",
      "Epoch 139/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3012 - acc: 0.8920\n",
      "Epoch 140/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3001 - acc: 0.8960\n",
      "Epoch 141/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3164 - acc: 0.8890\n",
      "Epoch 142/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3093 - acc: 0.8900\n",
      "Epoch 143/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3125 - acc: 0.8909\n",
      "Epoch 144/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2874 - acc: 0.8972\n",
      "Epoch 145/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2950 - acc: 0.8959\n",
      "Epoch 146/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2995 - acc: 0.8940\n",
      "Epoch 147/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3064 - acc: 0.8939\n",
      "Epoch 148/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3012 - acc: 0.8941\n",
      "Epoch 149/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3029 - acc: 0.8931\n",
      "Epoch 150/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2977 - acc: 0.8962\n",
      "Epoch 151/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.3012 - acc: 0.8941\n",
      "Epoch 152/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2996 - acc: 0.8955\n",
      "Epoch 153/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2905 - acc: 0.8984\n",
      "Epoch 154/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2826 - acc: 0.9005\n",
      "Epoch 155/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2876 - acc: 0.8994\n",
      "Epoch 156/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3000 - acc: 0.8946\n",
      "Epoch 157/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2941 - acc: 0.8956\n",
      "Epoch 158/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2913 - acc: 0.8945\n",
      "Epoch 159/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2883 - acc: 0.8994\n",
      "Epoch 160/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2934 - acc: 0.8931\n",
      "Epoch 161/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2824 - acc: 0.8997\n",
      "Epoch 162/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2779 - acc: 0.9022\n",
      "Epoch 163/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2861 - acc: 0.9002\n",
      "Epoch 164/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2801 - acc: 0.9040\n",
      "Epoch 165/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2741 - acc: 0.9042\n",
      "Epoch 166/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2791 - acc: 0.9009\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2698 - acc: 0.9014\n",
      "Epoch 168/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2776 - acc: 0.9032\n",
      "Epoch 169/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2797 - acc: 0.9062\n",
      "Epoch 170/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2641 - acc: 0.9091\n",
      "Epoch 171/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2704 - acc: 0.9077\n",
      "Epoch 172/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2707 - acc: 0.9034\n",
      "Epoch 173/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2797 - acc: 0.8981\n",
      "Epoch 174/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2709 - acc: 0.9030\n",
      "Epoch 175/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2730 - acc: 0.9069\n",
      "Epoch 176/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2732 - acc: 0.9050\n",
      "Epoch 177/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2703 - acc: 0.9022\n",
      "Epoch 178/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2790 - acc: 0.9059\n",
      "Epoch 179/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2710 - acc: 0.9095\n",
      "Epoch 180/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2578 - acc: 0.9085\n",
      "Epoch 181/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2734 - acc: 0.9042\n",
      "Epoch 182/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2766 - acc: 0.9036\n",
      "Epoch 183/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2726 - acc: 0.9056\n",
      "Epoch 184/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2687 - acc: 0.9079\n",
      "Epoch 185/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2619 - acc: 0.9071\n",
      "Epoch 186/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2575 - acc: 0.9133\n",
      "Epoch 187/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2668 - acc: 0.9093\n",
      "Epoch 188/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2758 - acc: 0.9049\n",
      "Epoch 189/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2671 - acc: 0.9101\n",
      "Epoch 190/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2598 - acc: 0.9125\n",
      "Epoch 191/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2549 - acc: 0.9109\n",
      "Epoch 192/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2683 - acc: 0.9101\n",
      "Epoch 193/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2548 - acc: 0.9126\n",
      "Epoch 194/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2693 - acc: 0.9107\n",
      "Epoch 195/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2516 - acc: 0.9128\n",
      "Epoch 196/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2543 - acc: 0.9121\n",
      "Epoch 197/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2549 - acc: 0.9149\n",
      "Epoch 198/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2555 - acc: 0.9116\n",
      "Epoch 199/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2599 - acc: 0.9114\n",
      "Epoch 200/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2497 - acc: 0.9124\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(train_data, train_y, batch_size=batch_size,shuffle = True),\n",
    "                        steps_per_epoch=train_data.shape[0] // batch_size,\n",
    "                        epochs=200,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2586 - acc: 0.9129\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2604 - acc: 0.9128\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2696 - acc: 0.9085\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2511 - acc: 0.9149\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2479 - acc: 0.9158\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2566 - acc: 0.9130\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2605 - acc: 0.9114\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2449 - acc: 0.9155\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2526 - acc: 0.9133\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2460 - acc: 0.9190\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2457 - acc: 0.9160\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2536 - acc: 0.9145\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2368 - acc: 0.9184\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2538 - acc: 0.9140\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2495 - acc: 0.9149\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2450 - acc: 0.9185\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2611 - acc: 0.9119\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2381 - acc: 0.9167\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2338 - acc: 0.9176\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2425 - acc: 0.9218\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2416 - acc: 0.9169\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2454 - acc: 0.9190\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2530 - acc: 0.9184\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2338 - acc: 0.9201\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2444 - acc: 0.9227\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2528 - acc: 0.9153\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2317 - acc: 0.9207\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2422 - acc: 0.9200\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2388 - acc: 0.9183\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2367 - acc: 0.9204\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2468 - acc: 0.9147\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2472 - acc: 0.9161\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2392 - acc: 0.9177\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2407 - acc: 0.9135\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2263 - acc: 0.9246\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2524 - acc: 0.9156\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2424 - acc: 0.9234\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2478 - acc: 0.9166\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2210 - acc: 0.9241\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2309 - acc: 0.9266\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2326 - acc: 0.9240\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2269 - acc: 0.9248\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2508 - acc: 0.9163\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2212 - acc: 0.9225\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2265 - acc: 0.9226\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2260 - acc: 0.9237\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2267 - acc: 0.9237\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2382 - acc: 0.9209\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2324 - acc: 0.9241\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2332 - acc: 0.9226\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2308 - acc: 0.9234\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2327 - acc: 0.9196\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2323 - acc: 0.9261\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2291 - acc: 0.9239\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2300 - acc: 0.9254\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2260 - acc: 0.9244\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2351 - acc: 0.9225\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2167 - acc: 0.9296\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2260 - acc: 0.9215\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2331 - acc: 0.9214\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2302 - acc: 0.9225\n",
      "Epoch 62/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2327 - acc: 0.9255\n",
      "Epoch 63/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2261 - acc: 0.9248\n",
      "Epoch 64/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2278 - acc: 0.9231\n",
      "Epoch 65/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2239 - acc: 0.9261\n",
      "Epoch 66/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2349 - acc: 0.9261\n",
      "Epoch 67/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2141 - acc: 0.9270\n",
      "Epoch 68/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2300 - acc: 0.9236\n",
      "Epoch 69/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2201 - acc: 0.9249\n",
      "Epoch 70/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2205 - acc: 0.9224\n",
      "Epoch 71/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2350 - acc: 0.9209\n",
      "Epoch 72/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2120 - acc: 0.9259\n",
      "Epoch 73/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2167 - acc: 0.9263\n",
      "Epoch 74/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2290 - acc: 0.9243\n",
      "Epoch 75/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2205 - acc: 0.9256\n",
      "Epoch 76/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2208 - acc: 0.9281\n",
      "Epoch 77/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2212 - acc: 0.9248\n",
      "Epoch 78/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2301 - acc: 0.9279\n",
      "Epoch 79/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2267 - acc: 0.9221\n",
      "Epoch 80/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2231 - acc: 0.9250\n",
      "Epoch 81/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2214 - acc: 0.9295\n",
      "Epoch 82/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2196 - acc: 0.9244\n",
      "Epoch 83/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2239 - acc: 0.9229\n",
      "Epoch 84/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2266 - acc: 0.9185\n",
      "Epoch 85/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2155 - acc: 0.9265\n",
      "Epoch 86/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2112 - acc: 0.9289\n",
      "Epoch 87/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2189 - acc: 0.9300\n",
      "Epoch 88/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2292 - acc: 0.9274\n",
      "Epoch 89/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2296 - acc: 0.9234\n",
      "Epoch 90/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2147 - acc: 0.9313\n",
      "Epoch 91/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2143 - acc: 0.9278\n",
      "Epoch 92/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2249 - acc: 0.9266\n",
      "Epoch 93/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2337 - acc: 0.9249\n",
      "Epoch 94/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2246 - acc: 0.9241\n",
      "Epoch 95/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2104 - acc: 0.9301\n",
      "Epoch 96/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2189 - acc: 0.9266\n",
      "Epoch 97/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2178 - acc: 0.9289\n",
      "Epoch 98/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2164 - acc: 0.9278\n",
      "Epoch 99/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2161 - acc: 0.9271\n",
      "Epoch 100/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2108 - acc: 0.9304\n",
      "Epoch 101/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2279 - acc: 0.9308\n",
      "Epoch 102/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2143 - acc: 0.9293\n",
      "Epoch 103/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2170 - acc: 0.9276\n",
      "Epoch 104/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2256 - acc: 0.9280\n",
      "Epoch 105/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2223 - acc: 0.9279\n",
      "Epoch 106/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2350 - acc: 0.9255\n",
      "Epoch 107/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2157 - acc: 0.9267\n",
      "Epoch 108/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2071 - acc: 0.9321\n",
      "Epoch 109/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2048 - acc: 0.9294\n",
      "Epoch 110/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2050 - acc: 0.9341\n",
      "Epoch 111/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2258 - acc: 0.9279\n",
      "Epoch 112/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2180 - acc: 0.9285\n",
      "Epoch 113/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2160 - acc: 0.9284\n",
      "Epoch 114/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2188 - acc: 0.9281\n",
      "Epoch 115/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2257 - acc: 0.9224\n",
      "Epoch 116/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2119 - acc: 0.9283\n",
      "Epoch 117/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2095 - acc: 0.9296\n",
      "Epoch 118/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2162 - acc: 0.9301\n",
      "Epoch 119/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2096 - acc: 0.9325\n",
      "Epoch 120/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2444 - acc: 0.9249\n",
      "Epoch 121/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2108 - acc: 0.9294\n",
      "Epoch 122/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2154 - acc: 0.9290\n",
      "Epoch 123/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2145 - acc: 0.9294\n",
      "Epoch 124/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2042 - acc: 0.9323\n",
      "Epoch 125/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2221 - acc: 0.9267\n",
      "Epoch 126/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.1922 - acc: 0.9344\n",
      "Epoch 127/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2035 - acc: 0.9346\n",
      "Epoch 128/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2185 - acc: 0.9326\n",
      "Epoch 129/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2080 - acc: 0.9303\n",
      "Epoch 130/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2130 - acc: 0.9323\n",
      "Epoch 131/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2107 - acc: 0.9300\n",
      "Epoch 132/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2241 - acc: 0.9285\n",
      "Epoch 133/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2029 - acc: 0.9323\n",
      "Epoch 134/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2109 - acc: 0.9303\n",
      "Epoch 135/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2139 - acc: 0.9255\n",
      "Epoch 136/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2057 - acc: 0.9305\n",
      "Epoch 137/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2034 - acc: 0.9306\n",
      "Epoch 138/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2103 - acc: 0.9278\n",
      "Epoch 139/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2167 - acc: 0.9284\n",
      "Epoch 140/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2282 - acc: 0.9311\n",
      "Epoch 141/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2186 - acc: 0.9314\n",
      "Epoch 142/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2078 - acc: 0.9304\n",
      "Epoch 143/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2046 - acc: 0.9304\n",
      "Epoch 144/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2104 - acc: 0.9306\n",
      "Epoch 145/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2028 - acc: 0.9341\n",
      "Epoch 146/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2099 - acc: 0.9311\n",
      "Epoch 147/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2037 - acc: 0.9323\n",
      "Epoch 148/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2113 - acc: 0.9333\n",
      "Epoch 149/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2194 - acc: 0.9284\n",
      "Epoch 150/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2052 - acc: 0.9299\n",
      "Epoch 151/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2201 - acc: 0.9255\n",
      "Epoch 152/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.1849 - acc: 0.9386\n",
      "Epoch 153/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2277 - acc: 0.9299\n",
      "Epoch 154/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2049 - acc: 0.9338\n",
      "Epoch 155/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2035 - acc: 0.9366\n",
      "Epoch 156/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2108 - acc: 0.9313\n",
      "Epoch 157/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.1977 - acc: 0.9347\n",
      "Epoch 158/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2123 - acc: 0.9309\n",
      "Epoch 159/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.1932 - acc: 0.9351\n",
      "Epoch 160/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2192 - acc: 0.9273\n",
      "Epoch 161/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2084 - acc: 0.9316\n",
      "Epoch 162/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2065 - acc: 0.9334\n",
      "Epoch 163/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2208 - acc: 0.9293\n",
      "Epoch 164/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2095 - acc: 0.9314\n",
      "Epoch 165/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2031 - acc: 0.9340\n",
      "Epoch 166/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2047 - acc: 0.9329\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2125 - acc: 0.9286\n",
      "Epoch 168/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2033 - acc: 0.9339\n",
      "Epoch 169/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.1942 - acc: 0.9391\n",
      "Epoch 170/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.1972 - acc: 0.9360\n",
      "Epoch 171/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.1958 - acc: 0.9371\n",
      "Epoch 172/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2047 - acc: 0.9346\n",
      "Epoch 173/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2146 - acc: 0.9325\n",
      "Epoch 174/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2028 - acc: 0.9351\n",
      "Epoch 175/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2068 - acc: 0.9343\n",
      "Epoch 176/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.1975 - acc: 0.9329\n",
      "Epoch 177/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2083 - acc: 0.9326\n",
      "Epoch 178/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2054 - acc: 0.9331\n",
      "Epoch 179/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.1978 - acc: 0.9343\n",
      "Epoch 180/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.1981 - acc: 0.9346\n",
      "Epoch 181/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.1989 - acc: 0.9341\n",
      "Epoch 182/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2156 - acc: 0.9351\n",
      "Epoch 183/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2127 - acc: 0.9294\n",
      "Epoch 184/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.1920 - acc: 0.9379\n",
      "Epoch 185/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2063 - acc: 0.9351\n",
      "Epoch 186/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2116 - acc: 0.9340\n",
      "Epoch 187/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2018 - acc: 0.9333\n",
      "Epoch 188/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.1992 - acc: 0.9319\n",
      "Epoch 189/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.1946 - acc: 0.9325\n",
      "Epoch 190/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2057 - acc: 0.9346\n",
      "Epoch 191/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.1983 - acc: 0.9368\n",
      "Epoch 192/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2057 - acc: 0.9340\n",
      "Epoch 193/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2041 - acc: 0.9379\n",
      "Epoch 194/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2104 - acc: 0.9336\n",
      "Epoch 195/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2026 - acc: 0.9325\n",
      "Epoch 196/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.2021 - acc: 0.9357\n",
      "Epoch 197/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.1974 - acc: 0.9369\n",
      "Epoch 198/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2040 - acc: 0.9347\n",
      "Epoch 199/200\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.1993 - acc: 0.9368\n",
      "Epoch 200/200\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2050 - acc: 0.9340\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(train_data, train_y, batch_size=batch_size,shuffle = True),\n",
    "                        steps_per_epoch=train_data.shape[0] // batch_size,\n",
    "                        epochs=200,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 256)       37120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               6553856   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 7,214,628\n",
      "Trainable params: 7,214,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model_3.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_3.h5\")\n",
    "print(loaded_model.summary())\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was also trained on the entire data but a considerable accuracy gain is observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 98.62%\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "                metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(test_data, test_y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After countless experimentation, this is a model that got 87% test accuracy and this is the one that I will be using to build the CSV file. The architecture is just a straightforward series of convolutions and Dropout and Dense layers. The validation, training loss and accuracy plot is also available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 24, 24, 256)       37120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               13107712  \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 13,899,812\n",
      "Trainable params: 13,899,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "batch_size = 64\n",
    "num_classes = 7\n",
    "epochs = 10\n",
    "input_shape = (28,28,1)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.85))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.85))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "print(model.summary())\n",
    "datagen.fit(train_data)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 11.9211 - acc: 0.2543 - val_loss: 12.0212 - val_acc: 0.2537\n",
      "Epoch 2/400\n",
      "112/112 [==============================] - 5s 49ms/step - loss: 11.7959 - acc: 0.2654 - val_loss: 11.9274 - val_acc: 0.2600\n",
      "Epoch 3/400\n",
      "112/112 [==============================] - 8s 74ms/step - loss: 11.6935 - acc: 0.2716 - val_loss: 10.0067 - val_acc: 0.3738\n",
      "Epoch 4/400\n",
      "112/112 [==============================] - 7s 63ms/step - loss: 10.5659 - acc: 0.3391 - val_loss: 9.0253 - val_acc: 0.4363\n",
      "Epoch 5/400\n",
      "112/112 [==============================] - 5s 47ms/step - loss: 4.9805 - acc: 0.4748 - val_loss: 0.8077 - val_acc: 0.6900\n",
      "Epoch 6/400\n",
      "112/112 [==============================] - 8s 68ms/step - loss: 0.8305 - acc: 0.6544 - val_loss: 0.5903 - val_acc: 0.7850\n",
      "Epoch 7/400\n",
      "112/112 [==============================] - 8s 71ms/step - loss: 0.7408 - acc: 0.7183 - val_loss: 0.5652 - val_acc: 0.7775\n",
      "Epoch 8/400\n",
      "112/112 [==============================] - 9s 84ms/step - loss: 0.6596 - acc: 0.7418 - val_loss: 0.5713 - val_acc: 0.7762\n",
      "Epoch 9/400\n",
      "112/112 [==============================] - 7s 67ms/step - loss: 0.6359 - acc: 0.7553 - val_loss: 0.5003 - val_acc: 0.8063\n",
      "Epoch 10/400\n",
      "112/112 [==============================] - 5s 48ms/step - loss: 0.6120 - acc: 0.7672 - val_loss: 0.5426 - val_acc: 0.7700\n",
      "Epoch 11/400\n",
      "112/112 [==============================] - 6s 52ms/step - loss: 0.5814 - acc: 0.7783 - val_loss: 0.4674 - val_acc: 0.8063\n",
      "Epoch 12/400\n",
      "112/112 [==============================] - 8s 70ms/step - loss: 0.5687 - acc: 0.7861 - val_loss: 0.5881 - val_acc: 0.7512\n",
      "Epoch 13/400\n",
      "112/112 [==============================] - 7s 61ms/step - loss: 0.5624 - acc: 0.7839 - val_loss: 0.4999 - val_acc: 0.7987\n",
      "Epoch 14/400\n",
      "112/112 [==============================] - 9s 83ms/step - loss: 0.5303 - acc: 0.7973 - val_loss: 0.4763 - val_acc: 0.8037\n",
      "Epoch 15/400\n",
      "112/112 [==============================] - 8s 75ms/step - loss: 0.5355 - acc: 0.7955 - val_loss: 0.4328 - val_acc: 0.8187\n",
      "Epoch 16/400\n",
      "112/112 [==============================] - 5s 43ms/step - loss: 0.4897 - acc: 0.8105 - val_loss: 0.4151 - val_acc: 0.8325\n",
      "Epoch 17/400\n",
      "112/112 [==============================] - 5s 45ms/step - loss: 0.4960 - acc: 0.8143 - val_loss: 0.4014 - val_acc: 0.8387\n",
      "Epoch 18/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.4822 - acc: 0.8132 - val_loss: 0.4082 - val_acc: 0.8413\n",
      "Epoch 19/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.4661 - acc: 0.8230 - val_loss: 0.3990 - val_acc: 0.8350\n",
      "Epoch 20/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.4722 - acc: 0.8235 - val_loss: 0.4195 - val_acc: 0.8413\n",
      "Epoch 21/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.4388 - acc: 0.8315 - val_loss: 0.4062 - val_acc: 0.8400\n",
      "Epoch 22/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.4573 - acc: 0.8241 - val_loss: 0.4071 - val_acc: 0.8475\n",
      "Epoch 23/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.4548 - acc: 0.8297 - val_loss: 0.4073 - val_acc: 0.8337\n",
      "Epoch 24/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.4316 - acc: 0.8320 - val_loss: 0.3882 - val_acc: 0.8562\n",
      "Epoch 25/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.4144 - acc: 0.8432 - val_loss: 0.3749 - val_acc: 0.8588\n",
      "Epoch 26/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.4313 - acc: 0.8316 - val_loss: 0.3933 - val_acc: 0.8562\n",
      "Epoch 27/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.4013 - acc: 0.8488 - val_loss: 0.3781 - val_acc: 0.8575\n",
      "Epoch 28/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.4008 - acc: 0.8456 - val_loss: 0.3787 - val_acc: 0.8488\n",
      "Epoch 29/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.4105 - acc: 0.8461 - val_loss: 0.4077 - val_acc: 0.8450\n",
      "Epoch 30/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3845 - acc: 0.8577 - val_loss: 0.3793 - val_acc: 0.8638\n",
      "Epoch 31/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3856 - acc: 0.8545 - val_loss: 0.3804 - val_acc: 0.8575\n",
      "Epoch 32/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3931 - acc: 0.8552 - val_loss: 0.3724 - val_acc: 0.8588\n",
      "Epoch 33/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3756 - acc: 0.8636 - val_loss: 0.3738 - val_acc: 0.8575\n",
      "Epoch 34/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3722 - acc: 0.8617 - val_loss: 0.3824 - val_acc: 0.8462\n",
      "Epoch 35/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3479 - acc: 0.8723 - val_loss: 0.3776 - val_acc: 0.8725\n",
      "Epoch 36/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3628 - acc: 0.8679 - val_loss: 0.3705 - val_acc: 0.8700\n",
      "Epoch 37/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3566 - acc: 0.8654 - val_loss: 0.3693 - val_acc: 0.8638\n",
      "Epoch 38/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3487 - acc: 0.8666 - val_loss: 0.3715 - val_acc: 0.8638\n",
      "Epoch 39/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3469 - acc: 0.8733 - val_loss: 0.4019 - val_acc: 0.8500\n",
      "Epoch 40/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3381 - acc: 0.8751 - val_loss: 0.3697 - val_acc: 0.8700\n",
      "Epoch 41/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3296 - acc: 0.8758 - val_loss: 0.4233 - val_acc: 0.8263\n",
      "Epoch 42/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3428 - acc: 0.8728 - val_loss: 0.3705 - val_acc: 0.8712\n",
      "Epoch 43/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3361 - acc: 0.8817 - val_loss: 0.3686 - val_acc: 0.8675\n",
      "Epoch 44/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3211 - acc: 0.8816 - val_loss: 0.3897 - val_acc: 0.8650\n",
      "Epoch 45/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3221 - acc: 0.8824 - val_loss: 0.3778 - val_acc: 0.8750\n",
      "Epoch 46/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3168 - acc: 0.8807 - val_loss: 0.3909 - val_acc: 0.8625\n",
      "Epoch 47/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3247 - acc: 0.8843 - val_loss: 0.3654 - val_acc: 0.8762\n",
      "Epoch 48/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3106 - acc: 0.8863 - val_loss: 0.3767 - val_acc: 0.8712\n",
      "Epoch 49/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3207 - acc: 0.8818 - val_loss: 0.3831 - val_acc: 0.8788\n",
      "Epoch 50/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3014 - acc: 0.8938 - val_loss: 0.3749 - val_acc: 0.8725\n",
      "Epoch 51/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2958 - acc: 0.8916 - val_loss: 0.3833 - val_acc: 0.8588\n",
      "Epoch 52/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2851 - acc: 0.8949 - val_loss: 0.4289 - val_acc: 0.8625\n",
      "Epoch 53/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2802 - acc: 0.8989 - val_loss: 0.3991 - val_acc: 0.8762\n",
      "Epoch 54/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.3036 - acc: 0.8933 - val_loss: 0.4077 - val_acc: 0.8725\n",
      "Epoch 55/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2935 - acc: 0.8941 - val_loss: 0.3801 - val_acc: 0.8775\n",
      "Epoch 56/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2845 - acc: 0.8994 - val_loss: 0.4377 - val_acc: 0.8700\n",
      "Epoch 57/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2826 - acc: 0.9021 - val_loss: 0.4180 - val_acc: 0.8738\n",
      "Epoch 58/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2971 - acc: 0.8951 - val_loss: 0.3987 - val_acc: 0.8738\n",
      "Epoch 59/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2854 - acc: 0.8962 - val_loss: 0.3918 - val_acc: 0.8738\n",
      "Epoch 60/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2739 - acc: 0.9029 - val_loss: 0.3957 - val_acc: 0.8738\n",
      "Epoch 61/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2733 - acc: 0.9032 - val_loss: 0.3787 - val_acc: 0.8725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.2798 - acc: 0.9037 - val_loss: 0.3995 - val_acc: 0.8712\n",
      "Epoch 63/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.2734 - acc: 0.9000 - val_loss: 0.3793 - val_acc: 0.8662\n",
      "Epoch 64/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.2787 - acc: 0.9004 - val_loss: 0.3962 - val_acc: 0.8750\n",
      "Epoch 65/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.2583 - acc: 0.9082 - val_loss: 0.3847 - val_acc: 0.8775\n",
      "Epoch 66/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2513 - acc: 0.9104 - val_loss: 0.4562 - val_acc: 0.8700\n",
      "Epoch 67/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2584 - acc: 0.9068 - val_loss: 0.4132 - val_acc: 0.8650\n",
      "Epoch 68/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2645 - acc: 0.9060 - val_loss: 0.3884 - val_acc: 0.8750\n",
      "Epoch 69/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2451 - acc: 0.9138 - val_loss: 0.4073 - val_acc: 0.8738\n",
      "Epoch 70/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2609 - acc: 0.9078 - val_loss: 0.4250 - val_acc: 0.8725\n",
      "Epoch 71/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2480 - acc: 0.9134 - val_loss: 0.4552 - val_acc: 0.8725\n",
      "Epoch 72/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2506 - acc: 0.9169 - val_loss: 0.3737 - val_acc: 0.8775\n",
      "Epoch 73/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2417 - acc: 0.9113 - val_loss: 0.4046 - val_acc: 0.8825\n",
      "Epoch 74/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2481 - acc: 0.9155 - val_loss: 0.4051 - val_acc: 0.8775\n",
      "Epoch 75/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2564 - acc: 0.9095 - val_loss: 0.4954 - val_acc: 0.8638\n",
      "Epoch 76/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2485 - acc: 0.9148 - val_loss: 0.4514 - val_acc: 0.8675\n",
      "Epoch 77/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2295 - acc: 0.9242 - val_loss: 0.4905 - val_acc: 0.8638\n",
      "Epoch 78/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2331 - acc: 0.9189 - val_loss: 0.4555 - val_acc: 0.8800\n",
      "Epoch 79/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2441 - acc: 0.9173 - val_loss: 0.4204 - val_acc: 0.8800\n",
      "Epoch 80/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2323 - acc: 0.9230 - val_loss: 0.4301 - val_acc: 0.8712\n",
      "Epoch 81/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2120 - acc: 0.9277 - val_loss: 0.4981 - val_acc: 0.8725\n",
      "Epoch 82/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2192 - acc: 0.9230 - val_loss: 0.4643 - val_acc: 0.8825\n",
      "Epoch 83/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2238 - acc: 0.9245 - val_loss: 0.4370 - val_acc: 0.8812\n",
      "Epoch 84/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2379 - acc: 0.9219 - val_loss: 0.4048 - val_acc: 0.8825\n",
      "Epoch 85/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2068 - acc: 0.9314 - val_loss: 0.4961 - val_acc: 0.8850\n",
      "Epoch 86/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2444 - acc: 0.9167 - val_loss: 0.4715 - val_acc: 0.8788\n",
      "Epoch 87/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2139 - acc: 0.9311 - val_loss: 0.4370 - val_acc: 0.8700\n",
      "Epoch 88/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2161 - acc: 0.9251 - val_loss: 0.4661 - val_acc: 0.8650\n",
      "Epoch 89/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2203 - acc: 0.9273 - val_loss: 0.4353 - val_acc: 0.8775\n",
      "Epoch 90/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2184 - acc: 0.9302 - val_loss: 0.5208 - val_acc: 0.8650\n",
      "Epoch 91/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2201 - acc: 0.9261 - val_loss: 0.4098 - val_acc: 0.8888\n",
      "Epoch 92/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2083 - acc: 0.9335 - val_loss: 0.4545 - val_acc: 0.8838\n",
      "Epoch 93/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2003 - acc: 0.9339 - val_loss: 0.4392 - val_acc: 0.8812\n",
      "Epoch 94/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2077 - acc: 0.9316 - val_loss: 0.4642 - val_acc: 0.8750\n",
      "Epoch 95/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1999 - acc: 0.9298 - val_loss: 0.4902 - val_acc: 0.8812\n",
      "Epoch 96/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2042 - acc: 0.9325 - val_loss: 0.4473 - val_acc: 0.8788\n",
      "Epoch 97/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2043 - acc: 0.9256 - val_loss: 0.4623 - val_acc: 0.8725\n",
      "Epoch 98/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.2029 - acc: 0.9328 - val_loss: 0.4746 - val_acc: 0.8800\n",
      "Epoch 99/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2043 - acc: 0.9332 - val_loss: 0.5118 - val_acc: 0.8788\n",
      "Epoch 100/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2071 - acc: 0.9347 - val_loss: 0.4602 - val_acc: 0.8788\n",
      "Epoch 101/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2013 - acc: 0.9350 - val_loss: 0.5004 - val_acc: 0.8838\n",
      "Epoch 102/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2015 - acc: 0.9355 - val_loss: 0.4533 - val_acc: 0.8812\n",
      "Epoch 103/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1938 - acc: 0.9374 - val_loss: 0.4977 - val_acc: 0.8750\n",
      "Epoch 104/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2039 - acc: 0.9351 - val_loss: 0.4705 - val_acc: 0.8725\n",
      "Epoch 105/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1986 - acc: 0.9379 - val_loss: 0.5152 - val_acc: 0.8762\n",
      "Epoch 106/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1754 - acc: 0.9446 - val_loss: 0.5509 - val_acc: 0.8800\n",
      "Epoch 107/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2035 - acc: 0.9342 - val_loss: 0.5514 - val_acc: 0.8875\n",
      "Epoch 108/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2104 - acc: 0.9340 - val_loss: 0.4875 - val_acc: 0.8788\n",
      "Epoch 109/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1795 - acc: 0.9404 - val_loss: 0.5493 - val_acc: 0.8725\n",
      "Epoch 110/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1899 - acc: 0.9348 - val_loss: 0.4339 - val_acc: 0.8738\n",
      "Epoch 111/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1880 - acc: 0.9381 - val_loss: 0.4918 - val_acc: 0.8725\n",
      "Epoch 112/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1826 - acc: 0.9414 - val_loss: 0.5251 - val_acc: 0.8725\n",
      "Epoch 113/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1881 - acc: 0.9406 - val_loss: 0.5840 - val_acc: 0.8688\n",
      "Epoch 114/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1784 - acc: 0.9418 - val_loss: 0.5483 - val_acc: 0.8850\n",
      "Epoch 115/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.2055 - acc: 0.9339 - val_loss: 0.5256 - val_acc: 0.8738\n",
      "Epoch 116/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1820 - acc: 0.9414 - val_loss: 0.5112 - val_acc: 0.8738\n",
      "Epoch 117/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1849 - acc: 0.9407 - val_loss: 0.5339 - val_acc: 0.8700\n",
      "Epoch 118/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1815 - acc: 0.9415 - val_loss: 0.4204 - val_acc: 0.8788\n",
      "Epoch 119/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1863 - acc: 0.9417 - val_loss: 0.6018 - val_acc: 0.8700\n",
      "Epoch 120/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1796 - acc: 0.9446 - val_loss: 0.6759 - val_acc: 0.8712\n",
      "Epoch 121/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1694 - acc: 0.9473 - val_loss: 0.5234 - val_acc: 0.8825\n",
      "Epoch 122/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1714 - acc: 0.9456 - val_loss: 0.4904 - val_acc: 0.8775\n",
      "Epoch 123/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1775 - acc: 0.9453 - val_loss: 0.6880 - val_acc: 0.8762\n",
      "Epoch 124/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1893 - acc: 0.9424 - val_loss: 0.5943 - val_acc: 0.8775\n",
      "Epoch 125/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1835 - acc: 0.9399 - val_loss: 0.4706 - val_acc: 0.8712\n",
      "Epoch 126/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1712 - acc: 0.9454 - val_loss: 0.5487 - val_acc: 0.8900\n",
      "Epoch 127/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1715 - acc: 0.9489 - val_loss: 0.5631 - val_acc: 0.8738\n",
      "Epoch 128/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1763 - acc: 0.9443 - val_loss: 0.5152 - val_acc: 0.8775\n",
      "Epoch 129/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1620 - acc: 0.9491 - val_loss: 0.6057 - val_acc: 0.8775\n",
      "Epoch 130/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1944 - acc: 0.9402 - val_loss: 0.4974 - val_acc: 0.8812\n",
      "Epoch 131/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1763 - acc: 0.9484 - val_loss: 0.5187 - val_acc: 0.8862\n",
      "Epoch 132/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1869 - acc: 0.9415 - val_loss: 0.5058 - val_acc: 0.8725\n",
      "Epoch 133/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1638 - acc: 0.9535 - val_loss: 0.5086 - val_acc: 0.8775\n",
      "Epoch 134/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1773 - acc: 0.9488 - val_loss: 0.5423 - val_acc: 0.8725\n",
      "Epoch 135/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1755 - acc: 0.9492 - val_loss: 0.5090 - val_acc: 0.8800\n",
      "Epoch 136/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1647 - acc: 0.9481 - val_loss: 0.5976 - val_acc: 0.8750\n",
      "Epoch 137/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1866 - acc: 0.9417 - val_loss: 0.4411 - val_acc: 0.8838\n",
      "Epoch 138/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1621 - acc: 0.9508 - val_loss: 0.5584 - val_acc: 0.8775\n",
      "Epoch 139/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1801 - acc: 0.9481 - val_loss: 0.4774 - val_acc: 0.8725\n",
      "Epoch 140/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1614 - acc: 0.9476 - val_loss: 0.5364 - val_acc: 0.8800\n",
      "Epoch 141/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1784 - acc: 0.9467 - val_loss: 0.4687 - val_acc: 0.8700\n",
      "Epoch 142/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1677 - acc: 0.9460 - val_loss: 0.5199 - val_acc: 0.8788\n",
      "Epoch 143/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1654 - acc: 0.9510 - val_loss: 0.4765 - val_acc: 0.8900\n",
      "Epoch 144/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1727 - acc: 0.9508 - val_loss: 0.3895 - val_acc: 0.8750\n",
      "Epoch 145/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1631 - acc: 0.9494 - val_loss: 0.5174 - val_acc: 0.8825\n",
      "Epoch 146/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1683 - acc: 0.9509 - val_loss: 0.4905 - val_acc: 0.8750\n",
      "Epoch 147/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1790 - acc: 0.9453 - val_loss: 0.4795 - val_acc: 0.8825\n",
      "Epoch 148/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1591 - acc: 0.9531 - val_loss: 0.5002 - val_acc: 0.8775\n",
      "Epoch 149/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1562 - acc: 0.9509 - val_loss: 0.5207 - val_acc: 0.8800\n",
      "Epoch 150/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1591 - acc: 0.9523 - val_loss: 0.7098 - val_acc: 0.8812\n",
      "Epoch 151/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1592 - acc: 0.9540 - val_loss: 0.4903 - val_acc: 0.8775\n",
      "Epoch 152/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1602 - acc: 0.9509 - val_loss: 0.5668 - val_acc: 0.8762\n",
      "Epoch 153/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1558 - acc: 0.9485 - val_loss: 0.6412 - val_acc: 0.8650\n",
      "Epoch 154/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1501 - acc: 0.9528 - val_loss: 0.5742 - val_acc: 0.8738\n",
      "Epoch 155/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1539 - acc: 0.9526 - val_loss: 0.6101 - val_acc: 0.8738\n",
      "Epoch 156/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1456 - acc: 0.9559 - val_loss: 0.4761 - val_acc: 0.8675\n",
      "Epoch 157/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1600 - acc: 0.9499 - val_loss: 0.5936 - val_acc: 0.8700\n",
      "Epoch 158/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1551 - acc: 0.9551 - val_loss: 0.5445 - val_acc: 0.8762\n",
      "Epoch 159/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1553 - acc: 0.9530 - val_loss: 0.5242 - val_acc: 0.8788\n",
      "Epoch 160/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1620 - acc: 0.9499 - val_loss: 0.4297 - val_acc: 0.8800\n",
      "Epoch 161/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1425 - acc: 0.9570 - val_loss: 0.6130 - val_acc: 0.8775\n",
      "Epoch 162/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1433 - acc: 0.9552 - val_loss: 0.5361 - val_acc: 0.8825\n",
      "Epoch 163/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1476 - acc: 0.9555 - val_loss: 0.5960 - val_acc: 0.8788\n",
      "Epoch 164/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1597 - acc: 0.9506 - val_loss: 0.6061 - val_acc: 0.8825\n",
      "Epoch 165/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1546 - acc: 0.9524 - val_loss: 0.6527 - val_acc: 0.8750\n",
      "Epoch 166/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1416 - acc: 0.9580 - val_loss: 0.6854 - val_acc: 0.8750\n",
      "Epoch 167/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1708 - acc: 0.9528 - val_loss: 0.5634 - val_acc: 0.8650\n",
      "Epoch 168/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1481 - acc: 0.9584 - val_loss: 0.5439 - val_acc: 0.8838\n",
      "Epoch 169/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1527 - acc: 0.9562 - val_loss: 0.6423 - val_acc: 0.8800\n",
      "Epoch 170/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1488 - acc: 0.9544 - val_loss: 0.6736 - val_acc: 0.8712\n",
      "Epoch 171/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1444 - acc: 0.9579 - val_loss: 0.5996 - val_acc: 0.8800\n",
      "Epoch 172/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1576 - acc: 0.9569 - val_loss: 0.5872 - val_acc: 0.8800\n",
      "Epoch 173/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1462 - acc: 0.9565 - val_loss: 0.7474 - val_acc: 0.8800\n",
      "Epoch 174/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1404 - acc: 0.9579 - val_loss: 0.6492 - val_acc: 0.8788\n",
      "Epoch 175/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1498 - acc: 0.9580 - val_loss: 0.6878 - val_acc: 0.8712\n",
      "Epoch 176/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1512 - acc: 0.9552 - val_loss: 0.6337 - val_acc: 0.8788\n",
      "Epoch 177/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1331 - acc: 0.9587 - val_loss: 0.6460 - val_acc: 0.8750\n",
      "Epoch 178/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1467 - acc: 0.9600 - val_loss: 0.7146 - val_acc: 0.8812\n",
      "Epoch 179/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1585 - acc: 0.9568 - val_loss: 0.6919 - val_acc: 0.8600\n",
      "Epoch 180/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1490 - acc: 0.9554 - val_loss: 0.6157 - val_acc: 0.8788\n",
      "Epoch 181/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1419 - acc: 0.9556 - val_loss: 0.6577 - val_acc: 0.8688\n",
      "Epoch 182/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1412 - acc: 0.9608 - val_loss: 0.6787 - val_acc: 0.8800\n",
      "Epoch 183/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1466 - acc: 0.9586 - val_loss: 0.6116 - val_acc: 0.8762\n",
      "Epoch 184/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1330 - acc: 0.9612 - val_loss: 0.6451 - val_acc: 0.8750\n",
      "Epoch 185/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1422 - acc: 0.9565 - val_loss: 0.5421 - val_acc: 0.8800\n",
      "Epoch 186/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1499 - acc: 0.9573 - val_loss: 0.5576 - val_acc: 0.8775\n",
      "Epoch 187/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1422 - acc: 0.9621 - val_loss: 0.7197 - val_acc: 0.8838\n",
      "Epoch 188/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1400 - acc: 0.9577 - val_loss: 0.5735 - val_acc: 0.8700\n",
      "Epoch 189/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1531 - acc: 0.9581 - val_loss: 0.5887 - val_acc: 0.8762\n",
      "Epoch 190/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1493 - acc: 0.9569 - val_loss: 0.5688 - val_acc: 0.8725\n",
      "Epoch 191/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1391 - acc: 0.9574 - val_loss: 0.5895 - val_acc: 0.8725\n",
      "Epoch 192/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1299 - acc: 0.9615 - val_loss: 0.6708 - val_acc: 0.8700\n",
      "Epoch 193/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1482 - acc: 0.9588 - val_loss: 0.7577 - val_acc: 0.8850\n",
      "Epoch 194/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1368 - acc: 0.9598 - val_loss: 0.7277 - val_acc: 0.8738\n",
      "Epoch 195/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1435 - acc: 0.9608 - val_loss: 0.6595 - val_acc: 0.8812\n",
      "Epoch 196/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1405 - acc: 0.9587 - val_loss: 0.5539 - val_acc: 0.8788\n",
      "Epoch 197/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1318 - acc: 0.9597 - val_loss: 0.8677 - val_acc: 0.8712\n",
      "Epoch 198/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1316 - acc: 0.9604 - val_loss: 0.6090 - val_acc: 0.8738\n",
      "Epoch 199/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1260 - acc: 0.9636 - val_loss: 0.7455 - val_acc: 0.8750\n",
      "Epoch 200/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1361 - acc: 0.9602 - val_loss: 0.7256 - val_acc: 0.8650\n",
      "Epoch 201/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1269 - acc: 0.9654 - val_loss: 0.7456 - val_acc: 0.8700\n",
      "Epoch 202/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1390 - acc: 0.9609 - val_loss: 0.6660 - val_acc: 0.8612\n",
      "Epoch 203/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1406 - acc: 0.9602 - val_loss: 0.6738 - val_acc: 0.8738\n",
      "Epoch 204/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1169 - acc: 0.9639 - val_loss: 0.7288 - val_acc: 0.8775\n",
      "Epoch 205/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1381 - acc: 0.9593 - val_loss: 0.6551 - val_acc: 0.8762\n",
      "Epoch 206/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1266 - acc: 0.9616 - val_loss: 0.6306 - val_acc: 0.8775\n",
      "Epoch 207/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1431 - acc: 0.9587 - val_loss: 0.8868 - val_acc: 0.8775\n",
      "Epoch 208/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1300 - acc: 0.9633 - val_loss: 0.6910 - val_acc: 0.8662\n",
      "Epoch 209/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1122 - acc: 0.9664 - val_loss: 0.5539 - val_acc: 0.8775\n",
      "Epoch 210/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1277 - acc: 0.9629 - val_loss: 0.6063 - val_acc: 0.8788\n",
      "Epoch 211/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1313 - acc: 0.9622 - val_loss: 0.6379 - val_acc: 0.8725\n",
      "Epoch 212/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1386 - acc: 0.9636 - val_loss: 0.6259 - val_acc: 0.8725\n",
      "Epoch 213/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1349 - acc: 0.9634 - val_loss: 0.6440 - val_acc: 0.8762\n",
      "Epoch 214/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1333 - acc: 0.9632 - val_loss: 0.7559 - val_acc: 0.8725\n",
      "Epoch 215/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1307 - acc: 0.9637 - val_loss: 0.6893 - val_acc: 0.8800\n",
      "Epoch 216/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1401 - acc: 0.9614 - val_loss: 0.5102 - val_acc: 0.8800\n",
      "Epoch 217/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1295 - acc: 0.9636 - val_loss: 0.6562 - val_acc: 0.8700\n",
      "Epoch 218/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1225 - acc: 0.9653 - val_loss: 0.5685 - val_acc: 0.8762\n",
      "Epoch 219/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1516 - acc: 0.9605 - val_loss: 0.6624 - val_acc: 0.8725\n",
      "Epoch 220/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1287 - acc: 0.9639 - val_loss: 0.5440 - val_acc: 0.8788\n",
      "Epoch 221/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1152 - acc: 0.9654 - val_loss: 0.7493 - val_acc: 0.8775\n",
      "Epoch 222/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1303 - acc: 0.9651 - val_loss: 0.6409 - val_acc: 0.8725\n",
      "Epoch 223/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1405 - acc: 0.9621 - val_loss: 0.7529 - val_acc: 0.8738\n",
      "Epoch 224/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1357 - acc: 0.9590 - val_loss: 0.7772 - val_acc: 0.8688\n",
      "Epoch 225/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1302 - acc: 0.9633 - val_loss: 0.5744 - val_acc: 0.8675\n",
      "Epoch 226/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1276 - acc: 0.9657 - val_loss: 0.6857 - val_acc: 0.8762\n",
      "Epoch 227/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1188 - acc: 0.9669 - val_loss: 0.6266 - val_acc: 0.8775\n",
      "Epoch 228/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1359 - acc: 0.9626 - val_loss: 0.6022 - val_acc: 0.8825\n",
      "Epoch 229/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1183 - acc: 0.9654 - val_loss: 0.5815 - val_acc: 0.8825\n",
      "Epoch 230/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1240 - acc: 0.9644 - val_loss: 0.6198 - val_acc: 0.8712\n",
      "Epoch 231/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1202 - acc: 0.9658 - val_loss: 0.7399 - val_acc: 0.8750\n",
      "Epoch 232/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1299 - acc: 0.9636 - val_loss: 0.5893 - val_acc: 0.8788\n",
      "Epoch 233/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1334 - acc: 0.9605 - val_loss: 0.6628 - val_acc: 0.8762\n",
      "Epoch 234/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1242 - acc: 0.9648 - val_loss: 0.6800 - val_acc: 0.8825\n",
      "Epoch 235/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1128 - acc: 0.9669 - val_loss: 0.7504 - val_acc: 0.8788\n",
      "Epoch 236/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1470 - acc: 0.9626 - val_loss: 0.7072 - val_acc: 0.8775\n",
      "Epoch 237/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1231 - acc: 0.9671 - val_loss: 0.7647 - val_acc: 0.8725\n",
      "Epoch 238/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1200 - acc: 0.9672 - val_loss: 0.6243 - val_acc: 0.8700\n",
      "Epoch 239/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1144 - acc: 0.9689 - val_loss: 0.7299 - val_acc: 0.8775\n",
      "Epoch 240/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1265 - acc: 0.9640 - val_loss: 0.7332 - val_acc: 0.8825\n",
      "Epoch 241/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1182 - acc: 0.9641 - val_loss: 0.7747 - val_acc: 0.8762\n",
      "Epoch 242/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1211 - acc: 0.9651 - val_loss: 0.5103 - val_acc: 0.8688\n",
      "Epoch 243/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1146 - acc: 0.9703 - val_loss: 0.7029 - val_acc: 0.8862\n",
      "Epoch 244/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1213 - acc: 0.9664 - val_loss: 0.7938 - val_acc: 0.8775\n",
      "Epoch 245/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1094 - acc: 0.9693 - val_loss: 0.7069 - val_acc: 0.8712\n",
      "Epoch 246/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1288 - acc: 0.9658 - val_loss: 0.7011 - val_acc: 0.8762\n",
      "Epoch 247/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1250 - acc: 0.9667 - val_loss: 0.5638 - val_acc: 0.8750\n",
      "Epoch 248/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1356 - acc: 0.9614 - val_loss: 0.7426 - val_acc: 0.8712\n",
      "Epoch 249/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1044 - acc: 0.9699 - val_loss: 0.8058 - val_acc: 0.8762\n",
      "Epoch 250/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1441 - acc: 0.9616 - val_loss: 0.5805 - val_acc: 0.8675\n",
      "Epoch 251/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1213 - acc: 0.9661 - val_loss: 0.8127 - val_acc: 0.8712\n",
      "Epoch 252/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1303 - acc: 0.9643 - val_loss: 0.6654 - val_acc: 0.8675\n",
      "Epoch 253/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1050 - acc: 0.9700 - val_loss: 0.6707 - val_acc: 0.8738\n",
      "Epoch 254/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1087 - acc: 0.9696 - val_loss: 0.6887 - val_acc: 0.8762\n",
      "Epoch 255/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1175 - acc: 0.9640 - val_loss: 0.7246 - val_acc: 0.8812\n",
      "Epoch 256/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1142 - acc: 0.9665 - val_loss: 0.7883 - val_acc: 0.8688\n",
      "Epoch 257/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1182 - acc: 0.9674 - val_loss: 0.6373 - val_acc: 0.8712\n",
      "Epoch 258/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1201 - acc: 0.9674 - val_loss: 0.6089 - val_acc: 0.8775\n",
      "Epoch 259/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1080 - acc: 0.9699 - val_loss: 0.6725 - val_acc: 0.8775\n",
      "Epoch 260/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1120 - acc: 0.9689 - val_loss: 0.7732 - val_acc: 0.8675\n",
      "Epoch 261/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1196 - acc: 0.9700 - val_loss: 0.7975 - val_acc: 0.8762\n",
      "Epoch 262/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1007 - acc: 0.9722 - val_loss: 0.7709 - val_acc: 0.8675\n",
      "Epoch 263/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1171 - acc: 0.9672 - val_loss: 0.7919 - val_acc: 0.8738\n",
      "Epoch 264/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1239 - acc: 0.9650 - val_loss: 0.6583 - val_acc: 0.8762\n",
      "Epoch 265/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1167 - acc: 0.9697 - val_loss: 0.7191 - val_acc: 0.8700\n",
      "Epoch 266/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1148 - acc: 0.9662 - val_loss: 0.8255 - val_acc: 0.8738\n",
      "Epoch 267/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1263 - acc: 0.9662 - val_loss: 0.8577 - val_acc: 0.8788\n",
      "Epoch 268/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1010 - acc: 0.9721 - val_loss: 0.7987 - val_acc: 0.8738\n",
      "Epoch 269/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1211 - acc: 0.9681 - val_loss: 0.7172 - val_acc: 0.8738\n",
      "Epoch 270/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1125 - acc: 0.9674 - val_loss: 0.7567 - val_acc: 0.8738\n",
      "Epoch 271/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1055 - acc: 0.9697 - val_loss: 0.9045 - val_acc: 0.8700\n",
      "Epoch 272/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1233 - acc: 0.9664 - val_loss: 0.7021 - val_acc: 0.8738\n",
      "Epoch 273/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1211 - acc: 0.9686 - val_loss: 0.8576 - val_acc: 0.8712\n",
      "Epoch 274/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1273 - acc: 0.9688 - val_loss: 0.7234 - val_acc: 0.8788\n",
      "Epoch 275/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1146 - acc: 0.9692 - val_loss: 0.8022 - val_acc: 0.8762\n",
      "Epoch 276/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1288 - acc: 0.9637 - val_loss: 0.7707 - val_acc: 0.8738\n",
      "Epoch 277/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1225 - acc: 0.9668 - val_loss: 0.7025 - val_acc: 0.8775\n",
      "Epoch 278/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1161 - acc: 0.9669 - val_loss: 0.7027 - val_acc: 0.8738\n",
      "Epoch 279/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1188 - acc: 0.9660 - val_loss: 0.7252 - val_acc: 0.8750\n",
      "Epoch 280/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1133 - acc: 0.9682 - val_loss: 0.7442 - val_acc: 0.8738\n",
      "Epoch 281/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1090 - acc: 0.9697 - val_loss: 0.8215 - val_acc: 0.8788\n",
      "Epoch 282/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0995 - acc: 0.9710 - val_loss: 0.5782 - val_acc: 0.8825\n",
      "Epoch 283/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1258 - acc: 0.9693 - val_loss: 0.5531 - val_acc: 0.8825\n",
      "Epoch 284/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1086 - acc: 0.9718 - val_loss: 0.7922 - val_acc: 0.8800\n",
      "Epoch 285/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1197 - acc: 0.9710 - val_loss: 0.7056 - val_acc: 0.8850\n",
      "Epoch 286/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1162 - acc: 0.9707 - val_loss: 0.7355 - val_acc: 0.8812\n",
      "Epoch 287/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1034 - acc: 0.9707 - val_loss: 0.7024 - val_acc: 0.8838\n",
      "Epoch 288/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1095 - acc: 0.9682 - val_loss: 0.6929 - val_acc: 0.8812\n",
      "Epoch 289/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1121 - acc: 0.9704 - val_loss: 0.7975 - val_acc: 0.8812\n",
      "Epoch 290/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1290 - acc: 0.9662 - val_loss: 0.6332 - val_acc: 0.8788\n",
      "Epoch 291/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1165 - acc: 0.9699 - val_loss: 0.7282 - val_acc: 0.8812\n",
      "Epoch 292/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1229 - acc: 0.9678 - val_loss: 0.7051 - val_acc: 0.8825\n",
      "Epoch 293/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1226 - acc: 0.9658 - val_loss: 0.6618 - val_acc: 0.8738\n",
      "Epoch 294/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1202 - acc: 0.9667 - val_loss: 0.5837 - val_acc: 0.8838\n",
      "Epoch 295/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1066 - acc: 0.9724 - val_loss: 0.7196 - val_acc: 0.8812\n",
      "Epoch 296/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1250 - acc: 0.9676 - val_loss: 0.6118 - val_acc: 0.8750\n",
      "Epoch 297/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1123 - acc: 0.9701 - val_loss: 0.6140 - val_acc: 0.8762\n",
      "Epoch 298/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0982 - acc: 0.9738 - val_loss: 0.7985 - val_acc: 0.8825\n",
      "Epoch 299/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1271 - acc: 0.9644 - val_loss: 0.8141 - val_acc: 0.8775\n",
      "Epoch 300/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1181 - acc: 0.9683 - val_loss: 0.7510 - val_acc: 0.8812\n",
      "Epoch 301/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1142 - acc: 0.9672 - val_loss: 0.8000 - val_acc: 0.8750\n",
      "Epoch 302/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1166 - acc: 0.9692 - val_loss: 0.5719 - val_acc: 0.8712\n",
      "Epoch 303/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1037 - acc: 0.9717 - val_loss: 0.7199 - val_acc: 0.8800\n",
      "Epoch 304/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1233 - acc: 0.9681 - val_loss: 0.6658 - val_acc: 0.8775\n",
      "Epoch 305/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1257 - acc: 0.9662 - val_loss: 0.6221 - val_acc: 0.8762\n",
      "Epoch 306/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0996 - acc: 0.9761 - val_loss: 0.6951 - val_acc: 0.8850\n",
      "Epoch 307/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1152 - acc: 0.9679 - val_loss: 0.7964 - val_acc: 0.8812\n",
      "Epoch 308/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1068 - acc: 0.9706 - val_loss: 0.6407 - val_acc: 0.8825\n",
      "Epoch 309/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1175 - acc: 0.9689 - val_loss: 0.8125 - val_acc: 0.8800\n",
      "Epoch 310/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1173 - acc: 0.9685 - val_loss: 0.6646 - val_acc: 0.8888\n",
      "Epoch 311/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.0951 - acc: 0.9756 - val_loss: 0.7696 - val_acc: 0.8938\n",
      "Epoch 312/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1114 - acc: 0.9694 - val_loss: 0.6997 - val_acc: 0.8862\n",
      "Epoch 313/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1272 - acc: 0.9654 - val_loss: 0.7273 - val_acc: 0.8850\n",
      "Epoch 314/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1009 - acc: 0.9722 - val_loss: 0.7283 - val_acc: 0.8888\n",
      "Epoch 315/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1148 - acc: 0.9699 - val_loss: 0.6660 - val_acc: 0.8850\n",
      "Epoch 316/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1088 - acc: 0.9729 - val_loss: 0.7311 - val_acc: 0.8900\n",
      "Epoch 317/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1038 - acc: 0.9718 - val_loss: 0.6490 - val_acc: 0.8862\n",
      "Epoch 318/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1096 - acc: 0.9690 - val_loss: 0.7241 - val_acc: 0.8875\n",
      "Epoch 319/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1090 - acc: 0.9722 - val_loss: 0.7329 - val_acc: 0.8875\n",
      "Epoch 320/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0976 - acc: 0.9724 - val_loss: 0.6854 - val_acc: 0.8888\n",
      "Epoch 321/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0953 - acc: 0.9746 - val_loss: 0.7810 - val_acc: 0.8812\n",
      "Epoch 322/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1000 - acc: 0.9717 - val_loss: 0.7908 - val_acc: 0.8800\n",
      "Epoch 323/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0963 - acc: 0.9731 - val_loss: 0.7945 - val_acc: 0.8788\n",
      "Epoch 324/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1302 - acc: 0.9685 - val_loss: 0.7640 - val_acc: 0.8775\n",
      "Epoch 325/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1111 - acc: 0.9731 - val_loss: 0.7362 - val_acc: 0.8700\n",
      "Epoch 326/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.0972 - acc: 0.9749 - val_loss: 0.6282 - val_acc: 0.8800\n",
      "Epoch 327/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1096 - acc: 0.9708 - val_loss: 0.6125 - val_acc: 0.8775\n",
      "Epoch 328/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1031 - acc: 0.9703 - val_loss: 0.8019 - val_acc: 0.8825\n",
      "Epoch 329/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0890 - acc: 0.9768 - val_loss: 0.7381 - val_acc: 0.8800\n",
      "Epoch 330/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1073 - acc: 0.9701 - val_loss: 0.8063 - val_acc: 0.8712\n",
      "Epoch 331/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1256 - acc: 0.9658 - val_loss: 0.6935 - val_acc: 0.8700\n",
      "Epoch 332/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1113 - acc: 0.9707 - val_loss: 0.7197 - val_acc: 0.8712\n",
      "Epoch 333/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1056 - acc: 0.9708 - val_loss: 0.6659 - val_acc: 0.8688\n",
      "Epoch 334/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1143 - acc: 0.9696 - val_loss: 0.7052 - val_acc: 0.8775\n",
      "Epoch 335/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1165 - acc: 0.9706 - val_loss: 0.6914 - val_acc: 0.8875\n",
      "Epoch 336/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1038 - acc: 0.9734 - val_loss: 0.6747 - val_acc: 0.8738\n",
      "Epoch 337/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1161 - acc: 0.9685 - val_loss: 0.6972 - val_acc: 0.8838\n",
      "Epoch 338/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1178 - acc: 0.9671 - val_loss: 0.7796 - val_acc: 0.8825\n",
      "Epoch 339/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0998 - acc: 0.9718 - val_loss: 0.8080 - val_acc: 0.8862\n",
      "Epoch 340/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1177 - acc: 0.9696 - val_loss: 0.7083 - val_acc: 0.8850\n",
      "Epoch 341/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1028 - acc: 0.9708 - val_loss: 0.7079 - val_acc: 0.8725\n",
      "Epoch 342/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.0904 - acc: 0.9752 - val_loss: 0.9474 - val_acc: 0.8812\n",
      "Epoch 343/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1193 - acc: 0.9671 - val_loss: 0.6191 - val_acc: 0.8738\n",
      "Epoch 344/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1046 - acc: 0.9718 - val_loss: 0.6457 - val_acc: 0.8750\n",
      "Epoch 345/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1207 - acc: 0.9689 - val_loss: 0.7907 - val_acc: 0.8775\n",
      "Epoch 346/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1013 - acc: 0.9764 - val_loss: 0.6231 - val_acc: 0.8812\n",
      "Epoch 347/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1073 - acc: 0.9734 - val_loss: 0.7756 - val_acc: 0.8738\n",
      "Epoch 348/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1159 - acc: 0.9747 - val_loss: 0.6058 - val_acc: 0.8850\n",
      "Epoch 349/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1013 - acc: 0.9736 - val_loss: 0.6316 - val_acc: 0.8775\n",
      "Epoch 350/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.0941 - acc: 0.9756 - val_loss: 0.8145 - val_acc: 0.8875\n",
      "Epoch 351/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1081 - acc: 0.9693 - val_loss: 0.8573 - val_acc: 0.8750\n",
      "Epoch 352/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0929 - acc: 0.9759 - val_loss: 0.7777 - val_acc: 0.8750\n",
      "Epoch 353/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1043 - acc: 0.9724 - val_loss: 0.7505 - val_acc: 0.8838\n",
      "Epoch 354/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1104 - acc: 0.9699 - val_loss: 0.8258 - val_acc: 0.8712\n",
      "Epoch 355/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1015 - acc: 0.9715 - val_loss: 0.6250 - val_acc: 0.8788\n",
      "Epoch 356/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1226 - acc: 0.9675 - val_loss: 0.6736 - val_acc: 0.8812\n",
      "Epoch 357/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0956 - acc: 0.9749 - val_loss: 0.8011 - val_acc: 0.8838\n",
      "Epoch 358/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0895 - acc: 0.9791 - val_loss: 0.7265 - val_acc: 0.8850\n",
      "Epoch 359/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1123 - acc: 0.9697 - val_loss: 0.7903 - val_acc: 0.8750\n",
      "Epoch 360/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1214 - acc: 0.9700 - val_loss: 0.7421 - val_acc: 0.8712\n",
      "Epoch 361/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1117 - acc: 0.9720 - val_loss: 0.8531 - val_acc: 0.8838\n",
      "Epoch 362/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0957 - acc: 0.9735 - val_loss: 0.8286 - val_acc: 0.8800\n",
      "Epoch 363/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1019 - acc: 0.9722 - val_loss: 0.8326 - val_acc: 0.8762\n",
      "Epoch 364/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0983 - acc: 0.9745 - val_loss: 0.7628 - val_acc: 0.8712\n",
      "Epoch 365/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1115 - acc: 0.9697 - val_loss: 0.8011 - val_acc: 0.8750\n",
      "Epoch 366/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1115 - acc: 0.9708 - val_loss: 0.8236 - val_acc: 0.8900\n",
      "Epoch 367/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1043 - acc: 0.9715 - val_loss: 0.6684 - val_acc: 0.8788\n",
      "Epoch 368/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1125 - acc: 0.9704 - val_loss: 0.7243 - val_acc: 0.8812\n",
      "Epoch 369/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1000 - acc: 0.9734 - val_loss: 0.8828 - val_acc: 0.8700\n",
      "Epoch 370/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1054 - acc: 0.9743 - val_loss: 0.6546 - val_acc: 0.8825\n",
      "Epoch 371/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1019 - acc: 0.9743 - val_loss: 0.7468 - val_acc: 0.8875\n",
      "Epoch 372/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0888 - acc: 0.9749 - val_loss: 0.8888 - val_acc: 0.8850\n",
      "Epoch 373/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1067 - acc: 0.9729 - val_loss: 0.8024 - val_acc: 0.8725\n",
      "Epoch 374/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1040 - acc: 0.9752 - val_loss: 0.7424 - val_acc: 0.8800\n",
      "Epoch 375/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.0892 - acc: 0.9756 - val_loss: 0.7008 - val_acc: 0.8825\n",
      "Epoch 376/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1089 - acc: 0.9696 - val_loss: 0.8649 - val_acc: 0.8762\n",
      "Epoch 377/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0947 - acc: 0.9748 - val_loss: 0.6824 - val_acc: 0.8888\n",
      "Epoch 378/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1125 - acc: 0.9717 - val_loss: 0.6950 - val_acc: 0.8850\n",
      "Epoch 379/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0971 - acc: 0.9742 - val_loss: 0.6459 - val_acc: 0.8838\n",
      "Epoch 380/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1052 - acc: 0.9710 - val_loss: 0.7383 - val_acc: 0.8862\n",
      "Epoch 381/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1067 - acc: 0.9725 - val_loss: 0.7323 - val_acc: 0.8825\n",
      "Epoch 382/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0910 - acc: 0.9764 - val_loss: 0.6893 - val_acc: 0.8825\n",
      "Epoch 383/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0985 - acc: 0.9773 - val_loss: 0.8426 - val_acc: 0.8738\n",
      "Epoch 384/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0950 - acc: 0.9741 - val_loss: 0.8914 - val_acc: 0.8788\n",
      "Epoch 385/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.0983 - acc: 0.9741 - val_loss: 0.7882 - val_acc: 0.8900\n",
      "Epoch 386/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1078 - acc: 0.9724 - val_loss: 0.7792 - val_acc: 0.8862\n",
      "Epoch 387/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1005 - acc: 0.9745 - val_loss: 0.7190 - val_acc: 0.8825\n",
      "Epoch 388/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0965 - acc: 0.9742 - val_loss: 0.7142 - val_acc: 0.8862\n",
      "Epoch 389/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1116 - acc: 0.9707 - val_loss: 0.6248 - val_acc: 0.8788\n",
      "Epoch 390/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0958 - acc: 0.9731 - val_loss: 0.7196 - val_acc: 0.8738\n",
      "Epoch 391/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0912 - acc: 0.9761 - val_loss: 0.7723 - val_acc: 0.8738\n",
      "Epoch 392/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1109 - acc: 0.9700 - val_loss: 0.6430 - val_acc: 0.8775\n",
      "Epoch 393/400\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.1059 - acc: 0.9729 - val_loss: 0.8576 - val_acc: 0.8862\n",
      "Epoch 394/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0911 - acc: 0.9768 - val_loss: 0.7808 - val_acc: 0.8912\n",
      "Epoch 395/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0993 - acc: 0.9743 - val_loss: 0.7462 - val_acc: 0.8788\n",
      "Epoch 396/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0972 - acc: 0.9754 - val_loss: 0.7749 - val_acc: 0.8700\n",
      "Epoch 397/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1003 - acc: 0.9731 - val_loss: 0.9297 - val_acc: 0.8738\n",
      "Epoch 398/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1024 - acc: 0.9720 - val_loss: 0.6306 - val_acc: 0.8712\n",
      "Epoch 399/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.0942 - acc: 0.9753 - val_loss: 0.8898 - val_acc: 0.8800\n",
      "Epoch 400/400\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.1096 - acc: 0.9734 - val_loss: 0.7921 - val_acc: 0.8762\n"
     ]
    }
   ],
   "source": [
    "history3 = model.fit_generator(datagen.flow(train_data, train_y, batch_size=batch_size,shuffle = True),\n",
    "                        steps_per_epoch=train_data.shape[0] // batch_size,\n",
    "                        epochs=400,shuffle = True, validation_data=(test_data, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "#print(history.history)\n",
    "from visualization import *\n",
    "historyFilePath = 'model-train-history3.png'\n",
    "trainingHistoryPlot(\"model history 3\", historyFilePath, history3.history)\n",
    "\n",
    "pickleFilePath = 'model-history3-dict.pickle'\n",
    "with open(pickleFilePath, 'wb') as handle:\n",
    "    pickle.dump(history3.history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_2_final.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model_2_final.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 87.62%\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model_2_final.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_2_final.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "loaded_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "                metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(test_data, test_y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SE-Resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also attempted building a SE-Resnet. But for some reason it dosen't converge on this dataset as well as I expected. It just performs on-par with my best model and So i don't believe the computational weight is justified but still, I felt like I should showcase it. I have trained it in a different notebook that I will put in repository but I'm adding the code here just in case. The training and evaluation results can be found in the other notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excite_block(input, ratio=16):\n",
    "    filter_kernels = input._keras_shape[-1]\n",
    "    z_shape = (1, 1, filter_kernels)\n",
    "    z = GlobalAveragePooling2D()(input)\n",
    "    z = Reshape(z_shape)(z)\n",
    "    s = Dense(filter_kernels//ratio, activation='relu', use_bias=False)(z)\n",
    "    s = Dense(filter_kernels, activation='sigmoid', use_bias=False)(s)\n",
    "    x = multiply([input, s])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_resnet_block_bottleneck(input,channels,_strides=(1, 1)):\n",
    "    chan_axis=-1\n",
    "    if(input._keras_shape[-1]!=channels or _strides!=(1,1)):\n",
    "        input = Conv2D(channels, (1, 1), padding='same', kernel_initializer='he_normal',\n",
    "                      use_bias=False, strides=_strides)(input)\n",
    "    \n",
    "    x = Conv2D(channels, (1, 1), padding='same', kernel_initializer='he_normal',\n",
    "                      use_bias=False, strides=_strides)(input)\n",
    "    x = BatchNormalization(axis=chan_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    \n",
    "    x = Conv2D(channels, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      use_bias=False, strides=_strides)(x)\n",
    "    x = BatchNormalization(axis=chan_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    \n",
    "    x = Conv2D(channels, (1, 1), padding='same', kernel_initializer='he_normal',\n",
    "                      use_bias=False, strides=_strides)(x)\n",
    "    x = BatchNormalization(axis=chan_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    \n",
    "    x = squeeze_excite_block(x)\n",
    "    out = add([x, input])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_resnet(input,filters = [64,128,256,256,512],depth = [6,8,12,8,6],num_classes=4, weight_decay=1e-4):\n",
    "# def se_resnet(input,filters = [64,128,256],depth = [6,8,6],num_classes=4, weight_decay=1e-4):\n",
    "    chan_axis=-1\n",
    "    x = Conv2D(filters[0], (3, 3), padding='same', use_bias=False, strides=(2, 2),\n",
    "               kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(input)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    for i in range(len(filters)):\n",
    "        x = se_resnet_block_bottleneck(x,filters[i],(2,2))\n",
    "        for j in range(depth[i]-1):\n",
    "            x = se_resnet_block_bottleneck(x,filters[i],(1,1))\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.85)(x)\n",
    "    x = Dense(num_classes, activation='softmax', use_bias=False)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape = (28, 28, 1),filters = [64,128,256,256,512],depth = [6,8,12,8,6],num_classes=4, weight_decay=1e-4):\n",
    "#def create_model(input_shape = (28, 28, 1),filters = [64,128,256],depth = [6,8,6],num_classes=4, weight_decay=1e-4):\n",
    "    input = Input(shape = input_shape)\n",
    "    x = se_resnet(input,filters,depth,num_classes)\n",
    "    model = Model(input, x)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 64)   576         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 64)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 64)     4096        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 2, 2, 64)     4096        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2, 2, 64)     256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2, 2, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 1, 1, 64)     36864       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1, 1, 64)     256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1, 1, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 1, 1, 64)     4096        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 1, 64)     256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1, 1, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 64)           0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 1, 4)      256         reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 1, 64)     256         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 1, 1, 64)     0           activation_3[0][0]               \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 4, 4, 64)     0           multiply_1[0][0]                 \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 4, 4, 64)     4096        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 64)     256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 4, 4, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 4, 4, 64)     36864       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 4, 4, 64)     256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 4, 4, 64)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 64)     4096        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 4, 4, 64)     256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 4, 4, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 64)           0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 1, 4)      256         reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1, 1, 64)     256         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 4, 4, 64)     0           activation_6[0][0]               \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 4, 4, 64)     0           multiply_2[0][0]                 \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 4, 64)     4096        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 4, 64)     256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 4, 4, 64)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 4, 4, 64)     36864       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 64)     256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 4, 4, 64)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 4, 4, 64)     4096        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 4, 64)     256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 4, 4, 64)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 64)           0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1, 1, 4)      256         reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1, 1, 64)     256         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 4, 4, 64)     0           activation_9[0][0]               \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 4, 4, 64)     0           multiply_3[0][0]                 \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 4, 64)     4096        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 4, 4, 64)     256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 4, 64)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 4, 4, 64)     36864       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 4, 64)     256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 4, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 64)     4096        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 64)     256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 4, 64)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 64)           0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1, 1, 4)      256         reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1, 1, 64)     256         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 4, 4, 64)     0           activation_12[0][0]              \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 4, 64)     0           multiply_4[0][0]                 \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 64)     4096        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 4, 4, 64)     256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 4, 64)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 4, 64)     36864       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 4, 4, 64)     256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 4, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 4, 64)     4096        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 64)     256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 4, 64)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 64)           0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1, 1, 4)      256         reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1, 1, 64)     256         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 4, 4, 64)     0           activation_15[0][0]              \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 4, 64)     0           multiply_5[0][0]                 \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 4, 64)     4096        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, 4, 64)     256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 4, 64)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 4, 64)     36864       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 4, 64)     256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 4, 64)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 4, 64)     4096        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 4, 64)     256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 4, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 64)           0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1, 1, 4)      256         reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1, 1, 64)     256         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 4, 4, 64)     0           activation_18[0][0]              \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 4, 64)     0           multiply_6[0][0]                 \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 2, 2, 128)    8192        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 1, 1, 128)    16384       conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 1, 1, 128)    512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 1, 1, 128)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 1, 1, 128)    147456      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 1, 1, 128)    512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1, 1, 128)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 1, 1, 128)    16384       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1, 1, 128)    512         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 1, 1, 128)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 128)          0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1, 1, 8)      1024        reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1, 1, 128)    1024        dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 1, 1, 128)    0           activation_21[0][0]              \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 2, 128)    0           multiply_7[0][0]                 \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 2, 2, 128)    16384       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 2, 2, 128)    512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 2, 2, 128)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 2, 2, 128)    147456      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 2, 2, 128)    512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 2, 2, 128)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 2, 2, 128)    16384       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 2, 2, 128)    512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 2, 2, 128)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_8 (Glo (None, 128)          0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1, 1, 8)      1024        reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1, 1, 128)    1024        dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 2, 2, 128)    0           activation_24[0][0]              \n",
      "                                                                 dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 2, 2, 128)    0           multiply_8[0][0]                 \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 2, 2, 128)    16384       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 2, 2, 128)    512         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 2, 2, 128)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 2, 2, 128)    147456      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 2, 2, 128)    512         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 2, 2, 128)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 2, 2, 128)    16384       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 2, 2, 128)    512         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 2, 2, 128)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_9 (Glo (None, 128)          0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1, 1, 8)      1024        reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 1, 1, 128)    1024        dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 2, 2, 128)    0           activation_27[0][0]              \n",
      "                                                                 dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 2, 2, 128)    0           multiply_9[0][0]                 \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 2, 2, 128)    16384       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 2, 2, 128)    512         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 2, 2, 128)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 2, 2, 128)    147456      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 2, 2, 128)    512         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 2, 2, 128)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 2, 2, 128)    16384       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 2, 2, 128)    512         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 2, 2, 128)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_10 (Gl (None, 128)          0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1, 1, 128)    0           global_average_pooling2d_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1, 1, 8)      1024        reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1, 1, 128)    1024        dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 2, 2, 128)    0           activation_30[0][0]              \n",
      "                                                                 dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 2, 2, 128)    0           multiply_10[0][0]                \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 2, 2, 128)    16384       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 2, 2, 128)    512         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 2, 2, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 2, 2, 128)    147456      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 2, 2, 128)    512         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 2, 2, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 2, 2, 128)    16384       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 2, 2, 128)    512         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 2, 2, 128)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_11 (Gl (None, 128)          0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 1, 1, 128)    0           global_average_pooling2d_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 1, 1, 8)      1024        reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 1, 1, 128)    1024        dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 2, 2, 128)    0           activation_33[0][0]              \n",
      "                                                                 dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 2, 2, 128)    0           multiply_11[0][0]                \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 2, 2, 128)    16384       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 2, 2, 128)    512         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 2, 2, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 2, 2, 128)    147456      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 2, 2, 128)    512         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 2, 2, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 2, 2, 128)    16384       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 2, 2, 128)    512         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 2, 2, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_12 (Gl (None, 128)          0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 1, 1, 128)    0           global_average_pooling2d_12[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1, 1, 8)      1024        reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 1, 1, 128)    1024        dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 2, 2, 128)    0           activation_36[0][0]              \n",
      "                                                                 dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 2, 2, 128)    0           multiply_12[0][0]                \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 2, 2, 128)    16384       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 2, 2, 128)    512         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 2, 2, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 2, 2, 128)    147456      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 2, 2, 128)    512         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 2, 2, 128)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 2, 2, 128)    16384       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 2, 2, 128)    512         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 2, 2, 128)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_13 (Gl (None, 128)          0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 1, 1, 128)    0           global_average_pooling2d_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 1, 1, 8)      1024        reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1, 1, 128)    1024        dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 2, 2, 128)    0           activation_39[0][0]              \n",
      "                                                                 dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 2, 2, 128)    0           multiply_13[0][0]                \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 2, 2, 128)    16384       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 2, 2, 128)    512         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 2, 2, 128)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 2, 2, 128)    147456      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 2, 2, 128)    512         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 2, 2, 128)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 2, 2, 128)    16384       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 2, 2, 128)    512         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 2, 2, 128)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_14 (Gl (None, 128)          0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 1, 1, 128)    0           global_average_pooling2d_14[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 1, 1, 8)      1024        reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 1, 1, 128)    1024        dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 2, 2, 128)    0           activation_42[0][0]              \n",
      "                                                                 dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 2, 2, 128)    0           multiply_14[0][0]                \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 1, 1, 256)    32768       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 1, 1, 256)    65536       conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 1, 1, 256)    1024        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 1, 1, 256)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 1, 1, 256)    589824      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 1, 1, 256)    1024        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 1, 1, 256)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 1, 1, 256)    65536       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 1, 1, 256)    1024        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 1, 1, 256)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_15 (Gl (None, 256)          0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_15[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 1, 1, 16)     4096        reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 1, 1, 256)    4096        dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 1, 1, 256)    0           activation_45[0][0]              \n",
      "                                                                 dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 1, 1, 256)    0           multiply_15[0][0]                \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 1, 1, 256)    65536       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 1, 1, 256)    1024        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 1, 1, 256)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 1, 1, 256)    589824      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 1, 1, 256)    1024        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1, 1, 256)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 1, 1, 256)    65536       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 1, 1, 256)    1024        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 1, 1, 256)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_16 (Gl (None, 256)          0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_16[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 1, 1, 16)     4096        reshape_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 1, 1, 256)    4096        dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 1, 1, 256)    0           activation_48[0][0]              \n",
      "                                                                 dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 1, 1, 256)    0           multiply_16[0][0]                \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 1, 1, 256)    65536       add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 1, 1, 256)    1024        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 1, 1, 256)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 1, 1, 256)    589824      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 1, 1, 256)    1024        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 1, 1, 256)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 1, 1, 256)    65536       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 1, 1, 256)    1024        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 1, 1, 256)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_17 (Gl (None, 256)          0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_17[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 1, 1, 16)     4096        reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 1, 1, 256)    4096        dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 1, 1, 256)    0           activation_51[0][0]              \n",
      "                                                                 dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 1, 1, 256)    0           multiply_17[0][0]                \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 1, 1, 256)    65536       add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 1, 1, 256)    1024        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 1, 1, 256)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 1, 1, 256)    589824      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 1, 1, 256)    1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 1, 1, 256)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 1, 1, 256)    65536       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 1, 1, 256)    1024        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 1, 1, 256)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_18 (Gl (None, 256)          0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_18[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 1, 1, 16)     4096        reshape_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 1, 1, 256)    4096        dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 1, 1, 256)    0           activation_54[0][0]              \n",
      "                                                                 dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 1, 1, 256)    0           multiply_18[0][0]                \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 1, 1, 256)    65536       add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 1, 1, 256)    1024        conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 1, 1, 256)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 1, 1, 256)    589824      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 1, 1, 256)    1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 1, 1, 256)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 1, 1, 256)    65536       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 1, 1, 256)    1024        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 1, 1, 256)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_19 (Gl (None, 256)          0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_19[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 1, 1, 16)     4096        reshape_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 1, 1, 256)    4096        dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 1, 1, 256)    0           activation_57[0][0]              \n",
      "                                                                 dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 1, 1, 256)    0           multiply_19[0][0]                \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 1, 1, 256)    65536       add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 1, 1, 256)    1024        conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 1, 1, 256)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 1, 1, 256)    589824      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 1, 1, 256)    1024        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 1, 1, 256)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 1, 1, 256)    65536       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 1, 1, 256)    1024        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1, 1, 256)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_20 (Gl (None, 256)          0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_20[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 1, 1, 16)     4096        reshape_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 1, 1, 256)    4096        dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 1, 1, 256)    0           activation_60[0][0]              \n",
      "                                                                 dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 1, 1, 256)    0           multiply_20[0][0]                \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 1, 1, 256)    65536       add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 1, 1, 256)    1024        conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 1, 1, 256)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 1, 1, 256)    589824      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 1, 1, 256)    1024        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 1, 1, 256)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 1, 1, 256)    65536       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 1, 1, 256)    1024        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 1, 1, 256)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_21 (Gl (None, 256)          0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_21[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 1, 1, 16)     4096        reshape_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 1, 1, 256)    4096        dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_21 (Multiply)          (None, 1, 1, 256)    0           activation_63[0][0]              \n",
      "                                                                 dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 1, 1, 256)    0           multiply_21[0][0]                \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 1, 1, 256)    65536       add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 1, 1, 256)    1024        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 1, 1, 256)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 1, 1, 256)    589824      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 1, 1, 256)    1024        conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 1, 1, 256)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 1, 1, 256)    65536       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 1, 1, 256)    1024        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 1, 1, 256)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_22 (Gl (None, 256)          0           activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_22 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_22[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 1, 1, 16)     4096        reshape_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 1, 1, 256)    4096        dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_22 (Multiply)          (None, 1, 1, 256)    0           activation_66[0][0]              \n",
      "                                                                 dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 1, 1, 256)    0           multiply_22[0][0]                \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 1, 1, 256)    65536       add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 1, 1, 256)    1024        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 1, 1, 256)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 1, 1, 256)    589824      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 1, 1, 256)    1024        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 1, 1, 256)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 1, 1, 256)    65536       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 1, 1, 256)    1024        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 1, 1, 256)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_23 (Gl (None, 256)          0           activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_23 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 1, 1, 16)     4096        reshape_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 1, 1, 256)    4096        dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_23 (Multiply)          (None, 1, 1, 256)    0           activation_69[0][0]              \n",
      "                                                                 dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 1, 1, 256)    0           multiply_23[0][0]                \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 1, 1, 256)    65536       add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 1, 1, 256)    1024        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 1, 1, 256)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 1, 1, 256)    589824      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 1, 1, 256)    1024        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 1, 1, 256)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 1, 1, 256)    65536       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 1, 1, 256)    1024        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 1, 1, 256)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_24 (Gl (None, 256)          0           activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_24 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_24[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 1, 1, 16)     4096        reshape_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 1, 1, 256)    4096        dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 1, 1, 256)    0           activation_72[0][0]              \n",
      "                                                                 dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 1, 1, 256)    0           multiply_24[0][0]                \n",
      "                                                                 add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 1, 1, 256)    65536       add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 1, 1, 256)    1024        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 1, 1, 256)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 1, 1, 256)    589824      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 1, 1, 256)    1024        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 1, 1, 256)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 1, 1, 256)    65536       activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 1, 1, 256)    1024        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 1, 1, 256)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_25 (Gl (None, 256)          0           activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_25 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_25[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 1, 1, 16)     4096        reshape_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 1, 1, 256)    4096        dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 1, 1, 256)    0           activation_75[0][0]              \n",
      "                                                                 dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 1, 1, 256)    0           multiply_25[0][0]                \n",
      "                                                                 add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 1, 1, 256)    65536       add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 1, 1, 256)    1024        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 1, 1, 256)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 1, 1, 256)    589824      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 1, 1, 256)    1024        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 1, 1, 256)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 1, 1, 256)    65536       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 1, 1, 256)    1024        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 1, 1, 256)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_26 (Gl (None, 256)          0           activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_26 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_26[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 1, 1, 16)     4096        reshape_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 1, 1, 256)    4096        dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_26 (Multiply)          (None, 1, 1, 256)    0           activation_78[0][0]              \n",
      "                                                                 dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 1, 1, 256)    0           multiply_26[0][0]                \n",
      "                                                                 add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 1, 1, 256)    65536       add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 1, 1, 256)    65536       conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 1, 1, 256)    1024        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 1, 1, 256)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 1, 1, 256)    589824      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 1, 1, 256)    1024        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 1, 1, 256)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 1, 1, 256)    65536       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 1, 1, 256)    1024        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 1, 1, 256)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_27 (Gl (None, 256)          0           activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_27 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_27[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 1, 1, 16)     4096        reshape_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 1, 1, 256)    4096        dense_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_27 (Multiply)          (None, 1, 1, 256)    0           activation_81[0][0]              \n",
      "                                                                 dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 1, 1, 256)    0           multiply_27[0][0]                \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 1, 1, 256)    65536       add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 1, 1, 256)    1024        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 1, 1, 256)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 1, 1, 256)    589824      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 1, 1, 256)    1024        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 1, 1, 256)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 1, 1, 256)    65536       activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 1, 1, 256)    1024        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 1, 1, 256)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_28 (Gl (None, 256)          0           activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_28 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_28[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 1, 1, 16)     4096        reshape_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 1, 1, 256)    4096        dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_28 (Multiply)          (None, 1, 1, 256)    0           activation_84[0][0]              \n",
      "                                                                 dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 1, 1, 256)    0           multiply_28[0][0]                \n",
      "                                                                 add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 1, 1, 256)    65536       add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 1, 1, 256)    1024        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 1, 1, 256)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 1, 1, 256)    589824      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 1, 1, 256)    1024        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 1, 1, 256)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 1, 1, 256)    65536       activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 1, 1, 256)    1024        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 1, 1, 256)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_29 (Gl (None, 256)          0           activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_29 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_29[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 1, 1, 16)     4096        reshape_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 1, 1, 256)    4096        dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_29 (Multiply)          (None, 1, 1, 256)    0           activation_87[0][0]              \n",
      "                                                                 dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 1, 1, 256)    0           multiply_29[0][0]                \n",
      "                                                                 add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 1, 1, 256)    65536       add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 1, 1, 256)    1024        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 1, 1, 256)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 1, 1, 256)    589824      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 1, 1, 256)    1024        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 1, 1, 256)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 1, 1, 256)    65536       activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 1, 1, 256)    1024        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 1, 1, 256)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_30 (Gl (None, 256)          0           activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_30 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_30[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 1, 1, 16)     4096        reshape_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 1, 1, 256)    4096        dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_30 (Multiply)          (None, 1, 1, 256)    0           activation_90[0][0]              \n",
      "                                                                 dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 1, 1, 256)    0           multiply_30[0][0]                \n",
      "                                                                 add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 1, 1, 256)    65536       add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 1, 1, 256)    1024        conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 1, 1, 256)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 1, 1, 256)    589824      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 1, 1, 256)    1024        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 1, 1, 256)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 1, 1, 256)    65536       activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 1, 1, 256)    1024        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 1, 1, 256)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_31 (Gl (None, 256)          0           activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_31 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_31[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 1, 1, 16)     4096        reshape_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 1, 1, 256)    4096        dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_31 (Multiply)          (None, 1, 1, 256)    0           activation_93[0][0]              \n",
      "                                                                 dense_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 1, 1, 256)    0           multiply_31[0][0]                \n",
      "                                                                 add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 1, 1, 256)    65536       add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 1, 1, 256)    1024        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 1, 1, 256)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 1, 1, 256)    589824      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 1, 1, 256)    1024        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 1, 1, 256)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 1, 1, 256)    65536       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 1, 1, 256)    1024        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 1, 1, 256)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_32 (Gl (None, 256)          0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_32 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_32[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 1, 1, 16)     4096        reshape_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 1, 1, 256)    4096        dense_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 1, 1, 256)    0           activation_96[0][0]              \n",
      "                                                                 dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 1, 1, 256)    0           multiply_32[0][0]                \n",
      "                                                                 add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 1, 1, 256)    65536       add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 1, 1, 256)    1024        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 1, 1, 256)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 1, 1, 256)    589824      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 1, 1, 256)    1024        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 1, 1, 256)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 1, 1, 256)    65536       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 1, 1, 256)    1024        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 1, 1, 256)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_33 (Gl (None, 256)          0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_33 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_33[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 1, 1, 16)     4096        reshape_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 1, 1, 256)    4096        dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 1, 1, 256)    0           activation_99[0][0]              \n",
      "                                                                 dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 1, 1, 256)    0           multiply_33[0][0]                \n",
      "                                                                 add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 1, 1, 256)    65536       add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 1, 1, 256)    1024        conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 1, 1, 256)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 1, 1, 256)    589824      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 1, 1, 256)    1024        conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 1, 1, 256)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 1, 1, 256)    65536       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 1, 1, 256)    1024        conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 1, 1, 256)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_34 (Gl (None, 256)          0           activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_34 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_34[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 1, 1, 16)     4096        reshape_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 1, 1, 256)    4096        dense_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 1, 1, 256)    0           activation_102[0][0]             \n",
      "                                                                 dense_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 1, 1, 256)    0           multiply_34[0][0]                \n",
      "                                                                 add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 1, 1, 512)    131072      add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 1, 1, 512)    262144      conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 1, 1, 512)    2048        conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 1, 1, 512)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 1, 1, 512)    2359296     activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 1, 1, 512)    2048        conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 1, 1, 512)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 1, 1, 512)    262144      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 1, 1, 512)    2048        conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 1, 1, 512)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_35 (Gl (None, 512)          0           activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_35 (Reshape)            (None, 1, 1, 512)    0           global_average_pooling2d_35[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 1, 1, 32)     16384       reshape_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 1, 1, 512)    16384       dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 1, 1, 512)    0           activation_105[0][0]             \n",
      "                                                                 dense_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 1, 1, 512)    0           multiply_35[0][0]                \n",
      "                                                                 conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 1, 1, 512)    262144      add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 1, 1, 512)    2048        conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 1, 1, 512)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 1, 1, 512)    2359296     activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 1, 1, 512)    2048        conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 1, 1, 512)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 1, 1, 512)    262144      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 1, 1, 512)    2048        conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 1, 1, 512)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_36 (Gl (None, 512)          0           activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_36 (Reshape)            (None, 1, 1, 512)    0           global_average_pooling2d_36[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 1, 1, 32)     16384       reshape_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 1, 1, 512)    16384       dense_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_36 (Multiply)          (None, 1, 1, 512)    0           activation_108[0][0]             \n",
      "                                                                 dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 1, 1, 512)    0           multiply_36[0][0]                \n",
      "                                                                 add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 1, 1, 512)    262144      add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 1, 1, 512)    2048        conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 1, 1, 512)    0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 1, 1, 512)    2359296     activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 1, 1, 512)    2048        conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 1, 1, 512)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 1, 1, 512)    262144      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 1, 1, 512)    2048        conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 1, 1, 512)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_37 (Gl (None, 512)          0           activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_37 (Reshape)            (None, 1, 1, 512)    0           global_average_pooling2d_37[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 1, 1, 32)     16384       reshape_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 1, 1, 512)    16384       dense_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_37 (Multiply)          (None, 1, 1, 512)    0           activation_111[0][0]             \n",
      "                                                                 dense_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 1, 1, 512)    0           multiply_37[0][0]                \n",
      "                                                                 add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 1, 1, 512)    262144      add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 1, 1, 512)    2048        conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 1, 1, 512)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 1, 1, 512)    2359296     activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 1, 1, 512)    2048        conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 1, 1, 512)    0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 1, 1, 512)    262144      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 1, 1, 512)    2048        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 1, 1, 512)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_38 (Gl (None, 512)          0           activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_38 (Reshape)            (None, 1, 1, 512)    0           global_average_pooling2d_38[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 1, 1, 32)     16384       reshape_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 1, 1, 512)    16384       dense_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_38 (Multiply)          (None, 1, 1, 512)    0           activation_114[0][0]             \n",
      "                                                                 dense_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 1, 1, 512)    0           multiply_38[0][0]                \n",
      "                                                                 add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 1, 1, 512)    262144      add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 1, 1, 512)    2048        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 1, 1, 512)    0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 1, 1, 512)    2359296     activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 1, 1, 512)    2048        conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 1, 1, 512)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 1, 1, 512)    262144      activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 1, 1, 512)    2048        conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 1, 1, 512)    0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_39 (Gl (None, 512)          0           activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_39 (Reshape)            (None, 1, 1, 512)    0           global_average_pooling2d_39[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_81 (Dense)                (None, 1, 1, 32)     16384       reshape_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 1, 1, 512)    16384       dense_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_39 (Multiply)          (None, 1, 1, 512)    0           activation_117[0][0]             \n",
      "                                                                 dense_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 1, 1, 512)    0           multiply_39[0][0]                \n",
      "                                                                 add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 1, 1, 512)    262144      add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 1, 1, 512)    2048        conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 1, 1, 512)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 1, 1, 512)    2359296     activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 1, 1, 512)    2048        conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 1, 1, 512)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 1, 1, 512)    262144      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 1, 1, 512)    2048        conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 1, 1, 512)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_40 (Gl (None, 512)          0           activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_40 (Reshape)            (None, 1, 1, 512)    0           global_average_pooling2d_40[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 1, 1, 32)     16384       reshape_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 1, 1, 512)    16384       dense_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_40 (Multiply)          (None, 1, 1, 512)    0           activation_120[0][0]             \n",
      "                                                                 dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 1, 1, 512)    0           multiply_40[0][0]                \n",
      "                                                                 add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_41 (Gl (None, 512)          0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           global_average_pooling2d_41[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 4)            2048        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 34,170,944\n",
      "Trainable params: 34,113,344\n",
      "Non-trainable params: 57,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test_image.pkl', 'rb') as f:\n",
    "    csv_data = pickle.load(f,encoding='utf-8')\n",
    "csv_data = np.array(csv_data).reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are sample results on some of the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1944 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "f, (ax1r, ax2r,ax3r) = plt.subplots(3, 2, figsize=(24, 27))\n",
    "ax1,ax2 = ax1r\n",
    "ax3,ax4 = ax2r\n",
    "ax5,ax6 = ax3r\n",
    "f.tight_layout()\n",
    "index = random.randint(0, len(csv_data))\n",
    "ax1.imshow(csv_data[450][:,:,0],cmap = 'gray')\n",
    "ax1.set_title(str(np.argmax(model.predict(csv_data[450].reshape(-1,28,28,1)))), fontsize=50)\n",
    "index = random.randint(0, len(csv_data))\n",
    "ax2.imshow(csv_data[index][:,:,0],cmap='gray')\n",
    "ax2.set_title(str(np.argmax(model.predict(csv_data[index].reshape(-1,28,28,1)))), fontsize=50)\n",
    "index = random.randint(0, len(csv_data))\n",
    "ax3.imshow(csv_data[index][:,:,0], cmap='gray')\n",
    "ax3.set_title(str(np.argmax(model.predict(csv_data[index].reshape(-1,28,28,1)))), fontsize=50)\n",
    "index = random.randint(0, len(csv_data))\n",
    "ax4.imshow(csv_data[index][:,:,0], cmap='gray')\n",
    "ax4.set_title(str(np.argmax(model.predict(csv_data[index].reshape(-1,28,28,1)))), fontsize=50)\n",
    "index = random.randint(0, len(csv_data))\n",
    "ax5.imshow(csv_data[index][:,:,0], cmap='gray')\n",
    "ax5.set_title(str(np.argmax(model.predict(csv_data[index].reshape(-1,28,28,1)))), fontsize=50)\n",
    "index = random.randint(0, len(csv_data))\n",
    "ax6.imshow(csv_data[index][:,:,0], cmap='gray')\n",
    "ax6.set_title(str(np.argmax(model.predict(csv_data[index].reshape(-1,28,28,1)))), fontsize=50)\n",
    "f.tight_layout()\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
